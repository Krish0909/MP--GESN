{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVLA83CoFrOr",
        "outputId": "f4409ade-1d8f-4e7a-fc23-3f5312fd54de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Har Har Mahadev\n"
          ]
        }
      ],
      "source": [
        "print(\"Har Har Mahadev\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAzEmzEYGKhK",
        "outputId": "24410996-8a35-4f98-a505-5579d959db12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.4 colorlog-6.9.0 optuna-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWwYg-K3F4jU",
        "outputId": "679688ae-b3d5-4704-b3b1-6b5bd113ab02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA A100-SXM4-40GB\n",
            "GPU Memory: 42.47 GB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 44/44 [01:49<00:00,  2.50s/it, loss=11.0406, primary=0.2708]\n",
            "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.36it/s]\n",
            "Training: 100%|██████████| 44/44 [01:50<00:00,  2.50s/it, loss=11.6181, primary=0.2757]\n",
            "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  4.91it/s]\n",
            "Training:  45%|████▌     | 20/44 [00:50<01:00,  2.50s/it, loss=9.5026, primary=0.2326]"
          ]
        }
      ],
      "source": [
        "# Research-Grade Multi-Perspective Graph ESN with Memory Optimization\n",
        "# Enhanced with EMA, mixed precision, curriculum learning, and comprehensive visualizations\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from scipy import signal\n",
        "from scipy.stats import pearsonr\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import kagglehub\n",
        "import json\n",
        "import seaborn as sns\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import optuna\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "from joblib import Memory\n",
        "import psutil\n",
        "from collections import defaultdict\n",
        "import logging\n",
        "\n",
        "# Set up environment\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Device and memory management\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Set random seed\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Memory cache for joblib\n",
        "cache_dir = './ecog_cache'\n",
        "os.makedirs(cache_dir, exist_ok=True)\n",
        "memory = Memory(cache_dir, verbose=0)\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Enhanced Configuration\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "class ResearchConfig:\n",
        "    def __init__(self):\n",
        "        # Data parameters - optimized for memory\n",
        "        self.NUM_ELECTRODES = 50\n",
        "        self.CONTEXT_SIZE = 256      # Reduced for memory\n",
        "        self.PREDICT_SIZE = 128      # Reduced for memory\n",
        "        self.SAMPLING_RATE = 1024\n",
        "        self.MAX_SEQUENCES = 500     # Reduced for initial training\n",
        "        self.BATCH_SIZE = 8          # Small batch for memory\n",
        "        self.GRADIENT_ACCUMULATION = 4  # Effective batch = 32\n",
        "        self.STRIDE = 64\n",
        "\n",
        "        # Word embedding parameters\n",
        "        self.WORD_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "        self.WORD_EMBEDDING_DIM = 384\n",
        "        self.CONTEXT_WORDS = 8\n",
        "        self.WORD_NOISE_SCALE = 0.1\n",
        "\n",
        "        # Reservoir parameters - optimized\n",
        "        self.NEURONS_PER_POPULATION = 768  # Reduced from 1024\n",
        "        self.SPECTRAL_RADIUS = 0.92\n",
        "        self.LEAKY_RATE = 0.35\n",
        "        self.RESERVOIR_DENSITY = 0.08\n",
        "        self.NOISE_LEVEL = 0.02\n",
        "\n",
        "        # Multi-perspective parameters\n",
        "        self.ELECTRODE_PERSPECTIVE_DIM = 96  # Reduced\n",
        "        self.COMMON_SPACE_DIM = 192         # Reduced\n",
        "        self.PERSPECTIVE_ATTENTION_HEADS = 4\n",
        "        self.USE_CROSS_ELECTRODE_ATTENTION = True\n",
        "\n",
        "        # Readout architecture\n",
        "        self.READOUT_TYPE = \"gru\"  # GRU uses less memory than transformer\n",
        "        self.READOUT_HIDDEN = 384\n",
        "        self.READOUT_LAYERS = 3\n",
        "        self.DROPOUT = 0.3\n",
        "\n",
        "        # Enhanced regularization\n",
        "        self.USE_EMA = True\n",
        "        self.EMA_DECAY = 0.999\n",
        "        self.USE_MIXUP = True\n",
        "        self.MIXUP_ALPHA = 0.2\n",
        "        self.LABEL_SMOOTHING = 0.1\n",
        "        self.USE_GRADIENT_PENALTY = True\n",
        "        self.GRADIENT_PENALTY_WEIGHT = 0.1\n",
        "\n",
        "        # Training parameters\n",
        "        self.LEARNING_RATE = 5e-4\n",
        "        self.MIN_LR = 1e-6\n",
        "        self.WEIGHT_DECAY = 1e-4\n",
        "        self.EPOCHS = 100\n",
        "        self.PATIENCE = 15\n",
        "        self.CLIP_GRAD_NORM = 1.0\n",
        "        self.WARMUP_EPOCHS = 5\n",
        "\n",
        "        # Mixed precision training\n",
        "        self.USE_AMP = True\n",
        "\n",
        "        # Curriculum learning\n",
        "        self.USE_CURRICULUM = True\n",
        "        self.CURRICULUM_STAGES = [\n",
        "            {'epochs': 10, 'predict_size': 32, 'context_size': 128},\n",
        "            {'epochs': 10, 'predict_size': 64, 'context_size': 192},\n",
        "            {'epochs': 80, 'predict_size': 128, 'context_size': 256}\n",
        "        ]\n",
        "\n",
        "        # Loss weights\n",
        "        self.PRIMARY_LOSS_WEIGHT = 1.0\n",
        "        self.RECONSTRUCTION_LOSS_WEIGHT = 0.15\n",
        "        self.CONSISTENCY_LOSS_WEIGHT = 0.1\n",
        "        self.DIVERSITY_LOSS_WEIGHT = 0.05\n",
        "        self.FREQ_LOSS_WEIGHT = 0.3\n",
        "        self.PHASE_LOSS_WEIGHT = 0.1\n",
        "\n",
        "        # Frequency bands\n",
        "        self.FREQ_BANDS = [\n",
        "            (30, 50),    # Low Gamma\n",
        "            (50, 80),    # Mid Gamma\n",
        "            (80, 120),   # High Gamma\n",
        "            (120, 200),  # Very High Gamma\n",
        "        ]\n",
        "\n",
        "        # Visualization\n",
        "        self.VIZ_EVERY_N_EPOCHS = 1\n",
        "        self.SAVE_EVERY_N_EPOCHS = 5\n",
        "\n",
        "        # Paths\n",
        "        self.OUTPUT_DIR = \"ecog_research_results\"\n",
        "        self.create_directories()\n",
        "\n",
        "    def create_directories(self):\n",
        "        \"\"\"Create all necessary directories.\"\"\"\n",
        "        dirs = [\n",
        "            self.OUTPUT_DIR,\n",
        "            os.path.join(self.OUTPUT_DIR, 'models'),\n",
        "            os.path.join(self.OUTPUT_DIR, 'visualizations'),\n",
        "            os.path.join(self.OUTPUT_DIR, 'logs'),\n",
        "            os.path.join(self.OUTPUT_DIR, 'checkpoints'),\n",
        "            os.path.join(self.OUTPUT_DIR, 'epoch_viz')\n",
        "        ]\n",
        "        for d in dirs:\n",
        "            os.makedirs(d, exist_ok=True)\n",
        "\n",
        "config = ResearchConfig()\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Memory Management Utilities\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"Clear GPU memory cache.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "        gc.collect()\n",
        "\n",
        "def get_memory_usage():\n",
        "    \"\"\"Get current memory usage.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return {\n",
        "            'gpu_allocated': torch.cuda.memory_allocated() / 1e9,\n",
        "            'gpu_reserved': torch.cuda.memory_reserved() / 1e9,\n",
        "            'ram_used': psutil.virtual_memory().used / 1e9,\n",
        "            'ram_percent': psutil.virtual_memory().percent\n",
        "        }\n",
        "    return {\n",
        "        'ram_used': psutil.virtual_memory().used / 1e9,\n",
        "        'ram_percent': psutil.virtual_memory().percent\n",
        "    }\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Data Loading with Memory Optimization\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "@memory.cache\n",
        "def load_ecog_subset(data_path, num_rows=100000):\n",
        "    \"\"\"Load a subset of ECoG data with caching.\"\"\"\n",
        "    logger.info(f\"Loading ECoG subset: {num_rows} rows\")\n",
        "\n",
        "    ecog_file = None\n",
        "    for root, dirs, files in os.walk(data_path):\n",
        "        for file in files:\n",
        "            if 'processed_ecog_data' in file and file.endswith('.csv'):\n",
        "                ecog_file = os.path.join(root, file)\n",
        "                break\n",
        "\n",
        "    if not ecog_file:\n",
        "        raise FileNotFoundError(\"Could not find ECoG data file\")\n",
        "\n",
        "    # Load subset\n",
        "    ecog_data = pd.read_csv(ecog_file, nrows=num_rows)\n",
        "    electrode_columns = [col for col in ecog_data.columns if col not in ['timestamp', 'word']]\n",
        "\n",
        "    return ecog_data, electrode_columns\n",
        "\n",
        "def prepare_data_efficient(ecog_data, electrode_columns, config):\n",
        "    \"\"\"Prepare data with memory-efficient processing.\"\"\"\n",
        "    # Select electrodes\n",
        "    selected_electrodes = electrode_columns[:config.NUM_ELECTRODES]\n",
        "\n",
        "    # Extract data\n",
        "    electrode_data = ecog_data[selected_electrodes].values\n",
        "    word_data = ecog_data['word'].values\n",
        "\n",
        "    # Remove NaN rows\n",
        "    valid_mask = ~np.isnan(electrode_data).any(axis=1)\n",
        "    electrode_data = electrode_data[valid_mask]\n",
        "    word_data = word_data[valid_mask]\n",
        "\n",
        "    # Scale data\n",
        "    scaler = RobustScaler()\n",
        "    electrode_data = scaler.fit_transform(electrode_data)\n",
        "\n",
        "    # Create stratified indices for better sampling\n",
        "    window_size = config.CONTEXT_SIZE + config.PREDICT_SIZE\n",
        "    indices = []\n",
        "\n",
        "    # Sample evenly across the dataset\n",
        "    total_samples = len(electrode_data) - window_size + 1\n",
        "    sample_rate = max(1, total_samples // config.MAX_SEQUENCES)\n",
        "\n",
        "    for i in range(0, total_samples, sample_rate):\n",
        "        indices.append(i)\n",
        "        if len(indices) >= config.MAX_SEQUENCES:\n",
        "            break\n",
        "\n",
        "    logger.info(f\"Created {len(indices)} sequences\")\n",
        "\n",
        "    return electrode_data, word_data, indices, scaler\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Enhanced Word Embedding Module\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "class OptimizedWordEmbedding(nn.Module):\n",
        "    \"\"\"Memory-optimized word embedding module.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name=None, device='cuda', max_cache_size=1000):\n",
        "        super().__init__()\n",
        "        if model_name is None:\n",
        "            model_name = config.WORD_MODEL_NAME\n",
        "\n",
        "        self.device = device\n",
        "        self.max_cache_size = max_cache_size\n",
        "\n",
        "        logger.info(f\"Loading language model: {model_name}\")\n",
        "\n",
        "        # Load model with reduced memory footprint\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.language_model = AutoModel.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch.float16 if config.USE_AMP else torch.float32\n",
        "        ).to(device)\n",
        "        self.language_model.eval()\n",
        "\n",
        "        # Freeze and optimize memory\n",
        "        for param in self.language_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.embedding_dim = self.language_model.config.hidden_size\n",
        "\n",
        "        # Projection layer\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(self.embedding_dim, config.WORD_EMBEDDING_DIM),\n",
        "            nn.LayerNorm(config.WORD_EMBEDDING_DIM),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "\n",
        "        # LRU cache with size limit\n",
        "        self.embedding_cache = {}\n",
        "        self.cache_usage = []\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _get_raw_embedding(self, text):\n",
        "        \"\"\"Get raw embedding without gradients.\"\"\"\n",
        "        inputs = self.tokenizer(\n",
        "            text,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=50\n",
        "        ).to(self.device)\n",
        "\n",
        "        with autocast(enabled=config.USE_AMP):\n",
        "            outputs = self.language_model(**inputs)\n",
        "\n",
        "        return outputs.last_hidden_state.float()\n",
        "\n",
        "    def _manage_cache(self, key):\n",
        "        \"\"\"Manage cache size with LRU policy.\"\"\"\n",
        "        if key in self.cache_usage:\n",
        "            self.cache_usage.remove(key)\n",
        "        self.cache_usage.append(key)\n",
        "\n",
        "        # Remove oldest if cache is too large\n",
        "        if len(self.embedding_cache) > self.max_cache_size:\n",
        "            oldest = self.cache_usage.pop(0)\n",
        "            del self.embedding_cache[oldest]\n",
        "\n",
        "    def get_word_embedding(self, word):\n",
        "        \"\"\"Get embedding with cache management.\"\"\"\n",
        "        if pd.isna(word) or word == \"\":\n",
        "            return torch.zeros(config.WORD_EMBEDDING_DIM, device=self.device)\n",
        "\n",
        "        # Check cache\n",
        "        if word in self.embedding_cache:\n",
        "            self._manage_cache(word)\n",
        "            return self.embedding_cache[word].clone()\n",
        "\n",
        "        # Compute embedding\n",
        "        raw_embedding = self._get_raw_embedding(word)\n",
        "        embedding = raw_embedding.mean(dim=1).squeeze()\n",
        "\n",
        "        # Project\n",
        "        with autocast(enabled=config.USE_AMP):\n",
        "            projected = self.projection(embedding)\n",
        "\n",
        "        # Cache\n",
        "        self.embedding_cache[word] = projected.detach()\n",
        "        self._manage_cache(word)\n",
        "\n",
        "        return projected\n",
        "\n",
        "    def get_context_embedding(self, words):\n",
        "        \"\"\"Get context embedding.\"\"\"\n",
        "        valid_words = [w for w in words if not pd.isna(w) and w != \"\"]\n",
        "\n",
        "        if not valid_words:\n",
        "            return torch.zeros(config.WORD_EMBEDDING_DIM, device=self.device)\n",
        "\n",
        "        sentence = \" \".join(valid_words[-5:])  # Last 5 words for memory\n",
        "\n",
        "        raw_embedding = self._get_raw_embedding(sentence)\n",
        "        embedding = raw_embedding[:, 0, :].squeeze()\n",
        "\n",
        "        with autocast(enabled=config.USE_AMP):\n",
        "            return self.projection(embedding)\n",
        "\n",
        "    def forward(self, word_sequence, context_words=None):\n",
        "        \"\"\"Process batch with memory efficiency.\"\"\"\n",
        "        current_embeddings = torch.stack([\n",
        "            self.get_word_embedding(word) for word in word_sequence\n",
        "        ])\n",
        "\n",
        "        if context_words is not None:\n",
        "            context_embeddings = torch.stack([\n",
        "                self.get_context_embedding(context) for context in context_words\n",
        "            ])\n",
        "        else:\n",
        "            context_embeddings = torch.zeros_like(current_embeddings)\n",
        "\n",
        "        # Add noise during training\n",
        "        if self.training and config.WORD_NOISE_SCALE > 0:\n",
        "            noise = torch.randn_like(current_embeddings) * config.WORD_NOISE_SCALE\n",
        "            current_embeddings = current_embeddings + noise\n",
        "            context_embeddings = context_embeddings + noise * 0.5\n",
        "\n",
        "        return current_embeddings, context_embeddings\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Exponential Moving Average for Model Weights\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "class EMA:\n",
        "    \"\"\"Exponential Moving Average for model parameters.\"\"\"\n",
        "\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.model = model\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        self.backup = {}\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"Update shadow parameters.\"\"\"\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = (\n",
        "                    self.decay * self.shadow[name] +\n",
        "                    (1 - self.decay) * param.data\n",
        "                )\n",
        "\n",
        "    def apply_shadow(self):\n",
        "        \"\"\"Apply shadow parameters to model.\"\"\"\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.backup[name] = param.data.clone()\n",
        "                param.data = self.shadow[name]\n",
        "\n",
        "    def restore(self):\n",
        "        \"\"\"Restore original parameters.\"\"\"\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad and name in self.backup:\n",
        "                param.data = self.backup[name]\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Enhanced Model Components\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "class EfficientElectrodeAttention(nn.Module):\n",
        "    \"\"\"Memory-efficient electrode attention.\"\"\"\n",
        "\n",
        "    def __init__(self, shared_dim, electrode_dim, num_heads=4):\n",
        "        super().__init__()\n",
        "        # Use less memory with grouped query attention\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = electrode_dim // num_heads\n",
        "\n",
        "        self.q_proj = nn.Linear(shared_dim, electrode_dim)\n",
        "        self.kv_proj = nn.Linear(shared_dim, electrode_dim * 2)\n",
        "        self.out_proj = nn.Linear(electrode_dim, electrode_dim)\n",
        "\n",
        "        self.norm = nn.LayerNorm(electrode_dim)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, L, D = x.shape\n",
        "\n",
        "        # Project\n",
        "        q = self.q_proj(x).view(B, L, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        kv = self.kv_proj(x).view(B, L, 2, self.num_heads, self.head_dim)\n",
        "        k, v = kv.unbind(2)\n",
        "        k = k.transpose(1, 2)\n",
        "        v = v.transpose(1, 2)\n",
        "\n",
        "        # Attention with dropout\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
        "        attn = F.softmax(scores, dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        # Apply attention\n",
        "        out = torch.matmul(attn, v)\n",
        "        out = out.transpose(1, 2).contiguous().view(B, L, -1)\n",
        "        out = self.out_proj(out)\n",
        "\n",
        "        return self.norm(out), attn\n",
        "\n",
        "class OptimizedReservoir(nn.Module):\n",
        "    \"\"\"Memory-optimized reservoir.\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, reservoir_size, config):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.reservoir_size = reservoir_size\n",
        "\n",
        "        # Sparse initialization for memory efficiency\n",
        "        self.register_buffer('W_in', torch.randn(reservoir_size, input_size) * 0.5)\n",
        "\n",
        "        # Sparse reservoir matrix\n",
        "        W = torch.randn(reservoir_size, reservoir_size)\n",
        "        mask = torch.rand(reservoir_size, reservoir_size) < config.RESERVOIR_DENSITY\n",
        "        W = W * mask.float()\n",
        "\n",
        "        # Normalize spectral radius\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "                eigenvalues = torch.linalg.eigvals(W)\n",
        "                radius = torch.max(torch.abs(eigenvalues)).item()\n",
        "                if radius > 0:\n",
        "                    W = W * (config.SPECTRAL_RADIUS / radius)\n",
        "            except:\n",
        "                W = W * config.SPECTRAL_RADIUS / (torch.norm(W) + 1e-6)\n",
        "\n",
        "        self.register_buffer('W', W)\n",
        "        self.bias = nn.Parameter(torch.zeros(reservoir_size))\n",
        "\n",
        "        self.leaky_rate = config.LEAKY_RATE\n",
        "        self.noise_level = config.NOISE_LEVEL\n",
        "\n",
        "        self.norm = nn.LayerNorm(reservoir_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        if hidden is None:\n",
        "            hidden = torch.zeros(batch_size, self.reservoir_size, device=x.device)\n",
        "\n",
        "        # Efficient computation\n",
        "        with autocast(enabled=config.USE_AMP):\n",
        "            pre_activation = x @ self.W_in.T + hidden @ self.W.T + self.bias\n",
        "            activation = torch.tanh(pre_activation)\n",
        "\n",
        "            # Leaky integration\n",
        "            new_hidden = (1 - self.leaky_rate) * hidden + self.leaky_rate * activation\n",
        "\n",
        "            # Add noise during training\n",
        "            if self.training and self.noise_level > 0:\n",
        "                new_hidden = new_hidden + torch.randn_like(new_hidden) * self.noise_level\n",
        "\n",
        "        return self.norm(new_hidden), new_hidden\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Main Model with Memory Optimization\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "class ResearchMPGESN(nn.Module):\n",
        "    \"\"\"Research-grade Multi-Perspective Graph ESN.\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_electrodes = config.NUM_ELECTRODES\n",
        "\n",
        "        # Word embeddings\n",
        "        self.word_embedder = OptimizedWordEmbedding(device=device)\n",
        "\n",
        "        # Feature projection\n",
        "        input_dim = config.NUM_ELECTRODES + 2 * config.WORD_EMBEDDING_DIM\n",
        "        self.feature_projection = nn.Sequential(\n",
        "            nn.Linear(input_dim, config.READOUT_HIDDEN),\n",
        "            nn.LayerNorm(config.READOUT_HIDDEN),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(config.DROPOUT)\n",
        "        )\n",
        "\n",
        "        # Reservoir\n",
        "        self.reservoir = OptimizedReservoir(\n",
        "            config.READOUT_HIDDEN,\n",
        "            config.NEURONS_PER_POPULATION,\n",
        "            config\n",
        "        )\n",
        "\n",
        "        # Efficient electrode attention\n",
        "        self.electrode_attentions = nn.ModuleList([\n",
        "            EfficientElectrodeAttention(\n",
        "                config.NEURONS_PER_POPULATION,\n",
        "                config.ELECTRODE_PERSPECTIVE_DIM,\n",
        "                config.PERSPECTIVE_ATTENTION_HEADS\n",
        "            ) for _ in range(config.NUM_ELECTRODES)\n",
        "        ])\n",
        "\n",
        "        # Common space projectors\n",
        "        self.common_projector = nn.Sequential(\n",
        "            nn.Linear(config.ELECTRODE_PERSPECTIVE_DIM, config.COMMON_SPACE_DIM),\n",
        "            nn.LayerNorm(config.COMMON_SPACE_DIM),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        # GRU readout (more memory efficient than transformer)\n",
        "        self.readout = nn.GRU(\n",
        "            input_size=config.NEURONS_PER_POPULATION,\n",
        "            hidden_size=config.READOUT_HIDDEN,\n",
        "            num_layers=config.READOUT_LAYERS,\n",
        "            batch_first=True,\n",
        "            dropout=config.DROPOUT if config.READOUT_LAYERS > 1 else 0,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.readout_proj = nn.Linear(config.READOUT_HIDDEN * 2, config.READOUT_HIDDEN)\n",
        "\n",
        "        # Prediction head with dropout - use max predict size for curriculum learning\n",
        "        max_predict_size = max([stage['predict_size'] for stage in config.CURRICULUM_STAGES]) if config.USE_CURRICULUM else config.PREDICT_SIZE\n",
        "        self.prediction_head = nn.Sequential(\n",
        "            nn.Linear(config.READOUT_HIDDEN, config.READOUT_HIDDEN // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(config.DROPOUT),\n",
        "            nn.Linear(config.READOUT_HIDDEN // 2, config.NUM_ELECTRODES * max_predict_size)\n",
        "        )\n",
        "        self.max_predict_size = max_predict_size\n",
        "\n",
        "        # Auxiliary decoders\n",
        "        self.electrode_decoders = nn.ModuleList([\n",
        "            nn.Linear(config.COMMON_SPACE_DIM, 1)\n",
        "            for _ in range(config.NUM_ELECTRODES)\n",
        "        ])\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"Initialize weights with Xavier/He initialization.\"\"\"\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.GRU):\n",
        "                for name, param in m.named_parameters():\n",
        "                    if 'weight' in name:\n",
        "                        nn.init.orthogonal_(param)\n",
        "                    elif 'bias' in name:\n",
        "                        nn.init.zeros_(param)\n",
        "\n",
        "    def forward(self, electrode_data, current_words, context_words, return_perspectives=False):\n",
        "        \"\"\"Forward pass with mixed precision.\"\"\"\n",
        "        batch_size, context_size, _ = electrode_data.shape\n",
        "\n",
        "        # Get word embeddings\n",
        "        word_embed, context_embed = self.word_embedder(current_words, context_words)\n",
        "\n",
        "        # Process sequence\n",
        "        reservoir_states = []\n",
        "        electrode_perspectives = []\n",
        "        common_representations = []\n",
        "        hidden = None\n",
        "\n",
        "        # Use gradient checkpointing for memory efficiency\n",
        "        for t in range(context_size):\n",
        "            # Combine inputs\n",
        "            electrode_t = electrode_data[:, t, :]\n",
        "            combined = torch.cat([electrode_t, word_embed, context_embed], dim=1)\n",
        "\n",
        "            # Feature projection\n",
        "            with autocast(enabled=self.config.USE_AMP):\n",
        "                features = self.feature_projection(combined)\n",
        "\n",
        "                # Reservoir processing\n",
        "                reservoir_out, hidden = self.reservoir(features, hidden)\n",
        "                reservoir_states.append(reservoir_out)\n",
        "\n",
        "                # Extract perspectives if needed\n",
        "                if return_perspectives and t % 4 == 0:  # Sample every 4th for memory\n",
        "                    perspectives_t = []\n",
        "                    common_t = []\n",
        "\n",
        "                    for e_idx in range(0, self.num_electrodes, 2):  # Sample electrodes\n",
        "                        persp, _ = self.electrode_attentions[e_idx](reservoir_out.unsqueeze(1))\n",
        "                        persp = persp.squeeze(1)\n",
        "                        common = self.common_projector(persp)\n",
        "\n",
        "                        perspectives_t.append(persp)\n",
        "                        common_t.append(common)\n",
        "\n",
        "                    electrode_perspectives.append(perspectives_t)\n",
        "                    common_representations.append(common_t)\n",
        "\n",
        "        # Stack states\n",
        "        reservoir_sequence = torch.stack(reservoir_states, dim=1)\n",
        "\n",
        "        # Readout\n",
        "        with autocast(enabled=self.config.USE_AMP):\n",
        "            readout_out, _ = self.readout(reservoir_sequence)\n",
        "            readout_out = self.readout_proj(readout_out)\n",
        "\n",
        "            # Global pooling\n",
        "            readout_features = readout_out.mean(dim=1)\n",
        "\n",
        "            # Generate predictions\n",
        "            predictions = self.prediction_head(readout_features)\n",
        "            predictions = predictions.view(batch_size, self.max_predict_size, self.num_electrodes)\n",
        "\n",
        "            # --- START OF CORRECTION ---\n",
        "            # Slice to current predict size using the attribute set by the curriculum learning loop\n",
        "            current_predict_size = self.current_predict_size if hasattr(self, 'current_predict_size') else self.config.PREDICT_SIZE\n",
        "            predictions = predictions[:, :current_predict_size, :]\n",
        "            # --- END OF CORRECTION ---\n",
        "\n",
        "        if return_perspectives:\n",
        "            return predictions, {\n",
        "                'perspectives': electrode_perspectives,\n",
        "                'common_space': common_representations\n",
        "            }\n",
        "        else:\n",
        "            return predictions\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Enhanced Loss Functions\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "class ResearchLoss(nn.Module):\n",
        "    \"\"\"Comprehensive loss with multiple components.\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.smooth_l1 = nn.SmoothL1Loss()\n",
        "\n",
        "    def compute_frequency_loss(self, pred, target):\n",
        "        \"\"\"Frequency domain loss.\"\"\"\n",
        "        # Use smaller FFT size for memory\n",
        "        n_fft = min(pred.shape[1], 256)\n",
        "\n",
        "        pred_fft = torch.fft.rfft(pred, n=n_fft, dim=1)\n",
        "        target_fft = torch.fft.rfft(target, n=n_fft, dim=1)\n",
        "\n",
        "        pred_mag = torch.abs(pred_fft)\n",
        "        target_mag = torch.abs(target_fft)\n",
        "\n",
        "        # Weighted frequency loss\n",
        "        freqs = torch.fft.rfftfreq(n_fft, d=1.0/self.config.SAMPLING_RATE).to(pred.device)\n",
        "\n",
        "        weights = torch.ones_like(freqs)\n",
        "        for low, high in self.config.FREQ_BANDS:\n",
        "            mask = (freqs >= low) & (freqs <= high)\n",
        "            weights[mask] = 2.0\n",
        "\n",
        "        freq_loss = torch.mean((pred_mag - target_mag)**2 * weights.unsqueeze(0).unsqueeze(-1))\n",
        "\n",
        "        return freq_loss\n",
        "\n",
        "    def compute_phase_loss(self, pred, target):\n",
        "        \"\"\"Phase consistency loss.\"\"\"\n",
        "        # Compute instantaneous phase\n",
        "        pred_analytic = torch.view_as_real(torch.fft.fft(pred, dim=1))\n",
        "        target_analytic = torch.view_as_real(torch.fft.fft(target, dim=1))\n",
        "\n",
        "        pred_phase = torch.atan2(pred_analytic[..., 1], pred_analytic[..., 0])\n",
        "        target_phase = torch.atan2(target_analytic[..., 1], target_analytic[..., 0])\n",
        "\n",
        "        # Circular distance\n",
        "        phase_diff = torch.remainder(pred_phase - target_phase + np.pi, 2 * np.pi) - np.pi\n",
        "        phase_loss = torch.mean(torch.abs(phase_diff))\n",
        "\n",
        "        return phase_loss\n",
        "\n",
        "    def compute_gradient_penalty(self, pred, target):\n",
        "        \"\"\"Gradient penalty for smoothness.\"\"\"\n",
        "        pred_grad = torch.diff(pred, dim=1)\n",
        "        target_grad = torch.diff(target, dim=1)\n",
        "\n",
        "        grad_loss = self.mse(pred_grad, target_grad)\n",
        "\n",
        "        return grad_loss\n",
        "\n",
        "    def forward(self, predictions, targets, electrode_perspectives_data=None, electrode_decoders=None):\n",
        "        \"\"\"Compute total loss.\"\"\"\n",
        "        # Primary losses\n",
        "        primary_loss = self.smooth_l1(predictions, targets)\n",
        "        freq_loss = self.compute_frequency_loss(predictions, targets)\n",
        "        phase_loss = self.compute_phase_loss(predictions, targets)\n",
        "\n",
        "        # Gradient penalty\n",
        "        grad_penalty = self.compute_gradient_penalty(predictions, targets)\n",
        "\n",
        "        # Auxiliary losses\n",
        "        reconstruction_loss = torch.tensor(0.0, device=predictions.device)\n",
        "        consistency_loss = torch.tensor(0.0, device=predictions.device)\n",
        "        diversity_loss = torch.tensor(0.0, device=predictions.device)\n",
        "\n",
        "        if electrode_perspectives_data is not None and electrode_decoders is not None:\n",
        "            common_space = electrode_perspectives_data.get('common_space', [])\n",
        "\n",
        "            if common_space:\n",
        "                # Reconstruction loss\n",
        "                for t_idx, common_t in enumerate(common_space):\n",
        "                    for e_idx, common_repr in enumerate(common_t):\n",
        "                        if e_idx * 2 < self.config.NUM_ELECTRODES:\n",
        "                            reconstructed = electrode_decoders[e_idx * 2](common_repr)\n",
        "                            target_mean = targets[:, :, e_idx * 2].mean(dim=1, keepdim=True)\n",
        "                            reconstruction_loss += self.mse(reconstructed, target_mean)\n",
        "\n",
        "                reconstruction_loss /= (len(common_space) * len(common_space[0]))\n",
        "\n",
        "                # Consistency loss\n",
        "                if len(common_space) > 1:\n",
        "                    for e_idx in range(len(common_space[0])):\n",
        "                        repr_sequence = torch.stack([common_space[t][e_idx] for t in range(len(common_space))], dim=1)\n",
        "                        temporal_diff = torch.diff(repr_sequence, dim=1)\n",
        "                        consistency_loss += torch.mean(temporal_diff ** 2)\n",
        "\n",
        "                    consistency_loss /= len(common_space[0])\n",
        "\n",
        "                # Diversity loss\n",
        "                for common_t in common_space:\n",
        "                    if len(common_t) > 1:\n",
        "                        reps = torch.stack(common_t, dim=1)\n",
        "                        reps_norm = F.normalize(reps, dim=-1)\n",
        "                        sim_matrix = torch.matmul(reps_norm, reps_norm.transpose(-2, -1))\n",
        "\n",
        "                        mask = ~torch.eye(len(common_t), device=reps.device, dtype=torch.bool)\n",
        "                        off_diag = sim_matrix[:, mask]\n",
        "\n",
        "                        diversity_loss += torch.mean(torch.relu(off_diag - 0.3))\n",
        "\n",
        "                diversity_loss /= len(common_space)\n",
        "\n",
        "        # Combine losses\n",
        "        total_loss = (\n",
        "            self.config.PRIMARY_LOSS_WEIGHT * primary_loss +\n",
        "            self.config.FREQ_LOSS_WEIGHT * freq_loss +\n",
        "            self.config.PHASE_LOSS_WEIGHT * phase_loss +\n",
        "            self.config.GRADIENT_PENALTY_WEIGHT * grad_penalty +\n",
        "            self.config.RECONSTRUCTION_LOSS_WEIGHT * reconstruction_loss +\n",
        "            self.config.CONSISTENCY_LOSS_WEIGHT * consistency_loss +\n",
        "            self.config.DIVERSITY_LOSS_WEIGHT * diversity_loss\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'total': total_loss,\n",
        "            'primary': primary_loss,\n",
        "            'freq': freq_loss,\n",
        "            'phase': phase_loss,\n",
        "            'grad_penalty': grad_penalty,\n",
        "            'reconstruction': reconstruction_loss,\n",
        "            'consistency': consistency_loss,\n",
        "            'diversity': diversity_loss\n",
        "        }\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Dataset with Augmentation\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "class AugmentedECoGDataset(Dataset):\n",
        "    \"\"\"Dataset with data augmentation.\"\"\"\n",
        "\n",
        "    def __init__(self, electrode_data, word_data, indices, context_size, predict_size, context_words=8):\n",
        "        self.electrode_data = electrode_data\n",
        "        self.word_data = word_data\n",
        "        self.indices = indices\n",
        "        self.context_size = context_size\n",
        "        self.predict_size = predict_size\n",
        "        self.context_words = context_words\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def augment_signal(self, signal):\n",
        "        \"\"\"Apply data augmentation to signal.\"\"\"\n",
        "        if np.random.random() > 0.5:\n",
        "            # Time shift\n",
        "            shift = np.random.randint(-5, 5)\n",
        "            signal = np.roll(signal, shift, axis=0)\n",
        "\n",
        "        if np.random.random() > 0.5:\n",
        "            # Amplitude scaling\n",
        "            scale = np.random.uniform(0.9, 1.1)\n",
        "            signal = signal * scale\n",
        "\n",
        "        if np.random.random() > 0.5:\n",
        "            # Add Gaussian noise\n",
        "            noise = np.random.normal(0, 0.02, signal.shape)\n",
        "            signal = signal + noise\n",
        "\n",
        "        return signal\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start_idx = self.indices[idx]\n",
        "\n",
        "        # Extract windows\n",
        "        context_data = self.electrode_data[start_idx:start_idx + self.context_size]\n",
        "        target_data = self.electrode_data[start_idx + self.context_size:\n",
        "                                         start_idx + self.context_size + self.predict_size]\n",
        "\n",
        "        # Apply augmentation during training\n",
        "        if hasattr(self, 'training') and self.training:\n",
        "            context_data = self.augment_signal(context_data.copy())\n",
        "\n",
        "        # Get word information\n",
        "        word_idx = start_idx + self.context_size // 2\n",
        "        current_word = self.word_data[word_idx] if word_idx < len(self.word_data) else \"\"\n",
        "\n",
        "        # Get context words\n",
        "        context_word_list = []\n",
        "        for i in range(self.context_words):\n",
        "            ctx_idx = word_idx - (i + 1) * 25\n",
        "            if ctx_idx >= 0:\n",
        "                word = self.word_data[ctx_idx]\n",
        "                if not pd.isna(word) and word != \"\":\n",
        "                    context_word_list.append(word)\n",
        "\n",
        "        return {\n",
        "            'electrode_context': torch.FloatTensor(context_data),\n",
        "            'electrode_target': torch.FloatTensor(target_data),\n",
        "            'current_word': current_word if not pd.isna(current_word) else \"\",\n",
        "            'context_words': context_word_list\n",
        "        }\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    \"\"\"Custom collate function.\"\"\"\n",
        "    electrode_context = torch.stack([item['electrode_context'] for item in batch])\n",
        "    electrode_target = torch.stack([item['electrode_target'] for item in batch])\n",
        "    current_words = [item['current_word'] for item in batch]\n",
        "    context_words = [item['context_words'] for item in batch]\n",
        "\n",
        "    return {\n",
        "        'electrode_context': electrode_context,\n",
        "        'electrode_target': electrode_target,\n",
        "        'current_words': current_words,\n",
        "        'context_words': context_words\n",
        "    }\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Training Functions with Visualization\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "def mixup_data(x, y, alpha=0.2):\n",
        "    \"\"\"Mixup augmentation.\"\"\"\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index]\n",
        "    mixed_y = lam * y + (1 - lam) * y[index]\n",
        "\n",
        "    return mixed_x, mixed_y, lam\n",
        "\n",
        "def save_epoch_visualization(model, val_loader, epoch, config, device):\n",
        "    \"\"\"Save visualizations for the epoch.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Get one batch for visualization\n",
        "    batch = next(iter(val_loader))\n",
        "\n",
        "    electrode_context = batch['electrode_context'].to(device)\n",
        "    electrode_target = batch['electrode_target'].to(device)\n",
        "    current_words = batch['current_words']\n",
        "    context_words = batch['context_words']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model(electrode_context, current_words, context_words, return_perspectives=False)\n",
        "\n",
        "    # Convert to numpy\n",
        "    context_np = electrode_context.cpu().numpy()\n",
        "    target_np = electrode_target.cpu().numpy()\n",
        "    pred_np = predictions.cpu().numpy()\n",
        "\n",
        "    # Create figure with subplots\n",
        "    fig = plt.figure(figsize=(20, 15))\n",
        "    gs = GridSpec(3, 2, figure=fig, hspace=0.3, wspace=0.2)\n",
        "\n",
        "    # Sample index\n",
        "    sample_idx = 0\n",
        "\n",
        "    # --- THIS IS THE CORRECTED BLOCK ---\n",
        "# Get current sequence sizes directly from the data arrays\n",
        "    current_context_size = context_np.shape[1]\n",
        "    current_predict_size = target_np.shape[1]\n",
        "\n",
        "    # Time axes - now created with the correct dynamic sizes\n",
        "    context_time = np.arange(current_context_size) / config.SAMPLING_RATE\n",
        "    predict_time = (np.arange(current_predict_size) / config.SAMPLING_RATE) + (current_context_size / config.SAMPLING_RATE)\n",
        "\n",
        "    # Plot 1: Signal predictions for multiple electrodes\n",
        "    electrodes_to_plot = [0, config.NUM_ELECTRODES//4, config.NUM_ELECTRODES//2, config.NUM_ELECTRODES-1]\n",
        "\n",
        "    for i, e_idx in enumerate(electrodes_to_plot[:2]):\n",
        "        ax = fig.add_subplot(gs[i, 0])\n",
        "\n",
        "        # Context\n",
        "        ax.plot(context_time, context_np[sample_idx, :, e_idx],\n",
        "               'b-', label='Context', alpha=0.7, linewidth=1.5)\n",
        "\n",
        "        # Actual vs Predicted\n",
        "        ax.plot(predict_time, target_np[sample_idx, :, e_idx],\n",
        "               'g-', label='Actual', linewidth=2)\n",
        "        ax.plot(predict_time, pred_np[sample_idx, :, e_idx],\n",
        "               'r--', label='Predicted', linewidth=2)\n",
        "\n",
        "        ax.axvline(x=context_time[-1], color='k', linestyle=':', alpha=0.5)\n",
        "        ax.set_xlabel('Time (s)')\n",
        "        ax.set_ylabel('Amplitude')\n",
        "        ax.set_title(f'Electrode {e_idx + 1}')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 2: Power spectra comparison\n",
        "    for i, e_idx in enumerate(electrodes_to_plot[:2]):\n",
        "        ax = fig.add_subplot(gs[i, 1])\n",
        "\n",
        "        # Compute power spectra\n",
        "        freqs, psd_actual = signal.welch(\n",
        "            target_np[sample_idx, :, e_idx],\n",
        "            fs=config.SAMPLING_RATE,\n",
        "            nperseg=min(64, current_predict_size)\n",
        "        )\n",
        "        _, psd_pred = signal.welch(\n",
        "            pred_np[sample_idx, :, e_idx],\n",
        "            fs=config.SAMPLING_RATE,\n",
        "            nperseg=min(64, current_predict_size)\n",
        "        )\n",
        "\n",
        "        ax.semilogy(freqs, psd_actual, 'g-', label='Actual', linewidth=2)\n",
        "        ax.semilogy(freqs, psd_pred, 'r--', label='Predicted', linewidth=2)\n",
        "\n",
        "        # Highlight gamma bands\n",
        "        for low, high in config.FREQ_BANDS:\n",
        "            ax.axvspan(low, high, alpha=0.2, color='yellow')\n",
        "\n",
        "        ax.set_xlabel('Frequency (Hz)')\n",
        "        ax.set_ylabel('PSD')\n",
        "        ax.set_title(f'Power Spectrum - Electrode {e_idx + 1}')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_xlim(0, 250)\n",
        "\n",
        "    # Plot 3: Error heatmap\n",
        "    ax = fig.add_subplot(gs[2, :])\n",
        "\n",
        "    # Compute errors\n",
        "    errors = np.abs(pred_np[sample_idx] - target_np[sample_idx])\n",
        "\n",
        "    im = ax.imshow(errors.T, aspect='auto', cmap='hot', interpolation='nearest')\n",
        "    ax.set_xlabel('Time steps')\n",
        "    ax.set_ylabel('Electrode')\n",
        "    ax.set_title('Prediction Error Heatmap')\n",
        "    plt.colorbar(im, ax=ax, label='Absolute Error')\n",
        "\n",
        "    # Add metrics\n",
        "    mse = np.mean((pred_np[sample_idx] - target_np[sample_idx])**2)\n",
        "    r2 = r2_score(target_np[sample_idx].flatten(), pred_np[sample_idx].flatten())\n",
        "\n",
        "    fig.suptitle(f'Epoch {epoch+1} - MSE: {mse:.4f}, R²: {r2:.4f}\\nWord: \"{current_words[sample_idx]}\"',\n",
        "                 fontsize=16)\n",
        "\n",
        "    # Save figure\n",
        "    save_path = os.path.join(config.OUTPUT_DIR, 'epoch_viz', f'epoch_{epoch+1:03d}.png')\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    logger.info(f\"Saved visualization for epoch {epoch+1}\")\n",
        "\n",
        "def train_epoch(model, train_loader, optimizer, criterion, scaler, device, config, ema=None):\n",
        "    \"\"\"Train for one epoch with gradient accumulation.\"\"\"\n",
        "    model.train()\n",
        "\n",
        "    losses = defaultdict(float)\n",
        "    num_batches = 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for batch_idx, batch in enumerate(progress_bar):\n",
        "        electrode_context = batch['electrode_context'].to(device)\n",
        "        electrode_target = batch['electrode_target'].to(device)\n",
        "        current_words = batch['current_words']\n",
        "        context_words = batch['context_words']\n",
        "\n",
        "        # Mixup augmentation\n",
        "        if config.USE_MIXUP and np.random.random() > 0.5:\n",
        "            electrode_context, electrode_target, lam = mixup_data(\n",
        "                electrode_context, electrode_target, config.MIXUP_ALPHA\n",
        "            )\n",
        "\n",
        "        # Forward pass with mixed precision\n",
        "        with autocast(enabled=config.USE_AMP):\n",
        "            predictions, perspective_data = model(\n",
        "                electrode_context, current_words, context_words, return_perspectives=True\n",
        "            )\n",
        "\n",
        "            loss_dict = criterion(\n",
        "                predictions, electrode_target,\n",
        "                electrode_perspectives_data=perspective_data,\n",
        "                electrode_decoders=model.electrode_decoders\n",
        "            )\n",
        "\n",
        "            loss = loss_dict['total'] / config.GRADIENT_ACCUMULATION\n",
        "\n",
        "        # Backward pass\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # Gradient accumulation\n",
        "        if (batch_idx + 1) % config.GRADIENT_ACCUMULATION == 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.CLIP_GRAD_NORM)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Update EMA\n",
        "            if ema is not None:\n",
        "                ema.update()\n",
        "\n",
        "        # Track losses\n",
        "        for k, v in loss_dict.items():\n",
        "            losses[k] += v.item()\n",
        "        num_batches += 1\n",
        "\n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': f\"{loss_dict['total'].item():.4f}\",\n",
        "            'primary': f\"{loss_dict['primary'].item():.4f}\"\n",
        "        })\n",
        "\n",
        "        # Clear cache periodically\n",
        "        if batch_idx % 50 == 0:\n",
        "            clear_gpu_memory()\n",
        "\n",
        "    # Average losses\n",
        "    for k in losses:\n",
        "        losses[k] /= num_batches\n",
        "\n",
        "    return dict(losses)\n",
        "\n",
        "def evaluate(model, val_loader, criterion, device, ema=None):\n",
        "    \"\"\"Evaluate model.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    if ema is not None:\n",
        "        ema.apply_shadow()\n",
        "\n",
        "    losses = defaultdict(float)\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    num_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            electrode_context = batch['electrode_context'].to(device)\n",
        "            electrode_target = batch['electrode_target'].to(device)\n",
        "            current_words = batch['current_words']\n",
        "            context_words = batch['context_words']\n",
        "\n",
        "            with autocast(enabled=config.USE_AMP):\n",
        "                predictions = model(\n",
        "                    electrode_context, current_words, context_words, return_perspectives=False\n",
        "                )\n",
        "\n",
        "                loss_dict = criterion(\n",
        "                    predictions, electrode_target,\n",
        "                    electrode_perspectives_data=None,\n",
        "                    electrode_decoders=None\n",
        "                )\n",
        "\n",
        "            # Track losses\n",
        "            for k, v in loss_dict.items():\n",
        "                losses[k] += v.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            # Store predictions\n",
        "            all_preds.append(predictions.cpu().numpy())\n",
        "            all_targets.append(electrode_target.cpu().numpy())\n",
        "\n",
        "    if ema is not None:\n",
        "        ema.restore()\n",
        "\n",
        "    # Compute metrics\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_targets = np.concatenate(all_targets)\n",
        "\n",
        "    # Flatten for metrics\n",
        "    preds_flat = all_preds.reshape(-1)\n",
        "    targets_flat = all_targets.reshape(-1)\n",
        "\n",
        "    mse = mean_squared_error(targets_flat, preds_flat)\n",
        "    r2 = r2_score(targets_flat, preds_flat)\n",
        "    corr, _ = pearsonr(preds_flat, targets_flat)\n",
        "\n",
        "    # Average losses\n",
        "    for k in losses:\n",
        "        losses[k] /= num_batches\n",
        "\n",
        "    losses['mse'] = mse\n",
        "    losses['r2'] = r2\n",
        "    losses['correlation'] = corr\n",
        "\n",
        "    return dict(losses)\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Main Training Function\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "def train_research_model(config):\n",
        "    \"\"\"Main training function with all research features.\"\"\"\n",
        "    logger.info(\"Starting research-grade MPGESN training\")\n",
        "\n",
        "    # Download and load data\n",
        "    data_path = kagglehub.dataset_download(\"arunramponnambalam/podcast-csv-aligned\")\n",
        "    ecog_data, electrode_columns = load_ecog_subset(data_path, num_rows=100000)\n",
        "\n",
        "    # For curriculum learning, use the maximum sizes for data preparation\n",
        "    original_context = config.CONTEXT_SIZE\n",
        "    original_predict = config.PREDICT_SIZE\n",
        "\n",
        "    if config.USE_CURRICULUM:\n",
        "        max_context = max([stage['context_size'] for stage in config.CURRICULUM_STAGES])\n",
        "        max_predict = max([stage['predict_size'] for stage in config.CURRICULUM_STAGES])\n",
        "        config.CONTEXT_SIZE = max_context\n",
        "        config.PREDICT_SIZE = max_predict\n",
        "\n",
        "    # Prepare data\n",
        "    electrode_data, word_data, indices, scaler = prepare_data_efficient(\n",
        "        ecog_data, electrode_columns, config\n",
        "    )\n",
        "\n",
        "    # Split data\n",
        "    train_idx, temp_idx = train_test_split(indices, test_size=0.3, random_state=SEED)\n",
        "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=SEED)\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = AugmentedECoGDataset(\n",
        "        electrode_data, word_data, train_idx,\n",
        "        config.CONTEXT_SIZE, config.PREDICT_SIZE, config.CONTEXT_WORDS\n",
        "    )\n",
        "    train_dataset.training = True\n",
        "\n",
        "    val_dataset = AugmentedECoGDataset(\n",
        "        electrode_data, word_data, val_idx,\n",
        "        config.CONTEXT_SIZE, config.PREDICT_SIZE, config.CONTEXT_WORDS\n",
        "    )\n",
        "\n",
        "    test_dataset = AugmentedECoGDataset(\n",
        "        electrode_data, word_data, test_idx,\n",
        "        config.CONTEXT_SIZE, config.PREDICT_SIZE, config.CONTEXT_WORDS\n",
        "    )\n",
        "\n",
        "    # Create loaders with pin memory\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=config.BATCH_SIZE,\n",
        "        shuffle=True, collate_fn=custom_collate_fn,\n",
        "        num_workers=2, pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset, batch_size=config.BATCH_SIZE * 2,\n",
        "        shuffle=False, collate_fn=custom_collate_fn,\n",
        "        num_workers=2, pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=config.BATCH_SIZE * 2,\n",
        "        shuffle=False, collate_fn=custom_collate_fn,\n",
        "        num_workers=2, pin_memory=True\n",
        "    )\n",
        "\n",
        "    logger.info(f\"Dataset sizes - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
        "\n",
        "    # Initialize model\n",
        "    model = ResearchMPGESN(config).to(device)\n",
        "\n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    logger.info(f\"Model parameters - Total: {total_params:,}, Trainable: {trainable_params:,}\")\n",
        "\n",
        "    # Initialize EMA\n",
        "    ema = EMA(model, decay=config.EMA_DECAY) if config.USE_EMA else None\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = ResearchLoss(config)\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=config.LEARNING_RATE,\n",
        "        weight_decay=config.WEIGHT_DECAY,\n",
        "        betas=(0.9, 0.999)\n",
        "    )\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = CosineAnnealingWarmRestarts(\n",
        "        optimizer, T_0=10, T_mult=2, eta_min=config.MIN_LR\n",
        "    )\n",
        "\n",
        "    # Mixed precision scaler\n",
        "    scaler = GradScaler(enabled=config.USE_AMP)\n",
        "\n",
        "    # Training history\n",
        "    history = defaultdict(list)\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        logger.info(f\"\\n{'='*60}\\nEpoch {epoch+1}/{config.EPOCHS}\\n{'='*60}\")\n",
        "\n",
        "        # Curriculum learning - update dataset sizes\n",
        "        current_context = original_context\n",
        "        current_predict = original_predict\n",
        "\n",
        "        if config.USE_CURRICULUM:\n",
        "            for stage in config.CURRICULUM_STAGES:\n",
        "                if epoch < stage['epochs']:\n",
        "                    current_context = stage['context_size']\n",
        "                    current_predict = stage['predict_size']\n",
        "                    logger.info(f\"Curriculum: context={current_context}, predict={current_predict}\")\n",
        "                    break\n",
        "\n",
        "            # Update model's current predict size\n",
        "            model.current_predict_size = current_predict\n",
        "\n",
        "            # Create new datasets with current sizes\n",
        "            train_dataset = AugmentedECoGDataset(\n",
        "                electrode_data, word_data, train_idx,\n",
        "                current_context, current_predict, config.CONTEXT_WORDS\n",
        "            )\n",
        "            train_dataset.training = True\n",
        "\n",
        "            val_dataset = AugmentedECoGDataset(\n",
        "                electrode_data, word_data, val_idx,\n",
        "                current_context, current_predict, config.CONTEXT_WORDS\n",
        "            )\n",
        "\n",
        "            # Recreate loaders\n",
        "            train_loader = DataLoader(\n",
        "                train_dataset, batch_size=config.BATCH_SIZE,\n",
        "                shuffle=True, collate_fn=custom_collate_fn,\n",
        "                num_workers=2, pin_memory=True\n",
        "            )\n",
        "\n",
        "            val_loader = DataLoader(\n",
        "                val_dataset, batch_size=config.BATCH_SIZE * 2,\n",
        "                shuffle=False, collate_fn=custom_collate_fn,\n",
        "                num_workers=2, pin_memory=True\n",
        "            )\n",
        "\n",
        "        # Train\n",
        "        train_losses = train_epoch(\n",
        "            model, train_loader, optimizer, criterion, scaler, device, config, ema\n",
        "        )\n",
        "\n",
        "        # Validate\n",
        "        val_losses = evaluate(model, val_loader, criterion, device, ema)\n",
        "\n",
        "        # Update scheduler\n",
        "        scheduler.step()\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        # Log results\n",
        "        logger.info(f\"Train - Total: {train_losses['total']:.4f}, Primary: {train_losses['primary']:.4f}\")\n",
        "        logger.info(f\"Val - Total: {val_losses['total']:.4f}, MSE: {val_losses['mse']:.4f}, R²: {val_losses['r2']:.4f}\")\n",
        "        logger.info(f\"Learning Rate: {current_lr:.6f}\")\n",
        "\n",
        "        # Save history\n",
        "        for k, v in train_losses.items():\n",
        "            history[f'train_{k}'].append(v)\n",
        "        for k, v in val_losses.items():\n",
        "            history[f'val_{k}'].append(v)\n",
        "        history['lr'].append(current_lr)\n",
        "\n",
        "        # Save visualizations\n",
        "        if (epoch + 1) % config.VIZ_EVERY_N_EPOCHS == 0:\n",
        "            save_epoch_visualization(model, val_loader, epoch, config, device)\n",
        "\n",
        "        # Model checkpointing\n",
        "        if val_losses['total'] < best_val_loss:\n",
        "            best_val_loss = val_losses['total']\n",
        "            patience_counter = 0\n",
        "\n",
        "            checkpoint = {\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'ema_state_dict': ema.shadow if ema else None,\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'scaler_state_dict': scaler.state_dict(),\n",
        "                'val_losses': val_losses,\n",
        "                'config': config.__dict__\n",
        "            }\n",
        "\n",
        "            torch.save(checkpoint, os.path.join(config.OUTPUT_DIR, 'models', 'best_model.pt'))\n",
        "            logger.info(f\"✅ Saved best model with val_loss: {best_val_loss:.4f}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Periodic checkpoint\n",
        "        if (epoch + 1) % config.SAVE_EVERY_N_EPOCHS == 0:\n",
        "            checkpoint_path = os.path.join(\n",
        "                config.OUTPUT_DIR, 'checkpoints', f'checkpoint_epoch_{epoch+1}.pt'\n",
        "            )\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'history': dict(history)\n",
        "            }, checkpoint_path)\n",
        "\n",
        "        # Early stopping\n",
        "        if patience_counter >= config.PATIENCE:\n",
        "            logger.info(f\"Early stopping after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "        # Memory management\n",
        "        clear_gpu_memory()\n",
        "        mem_usage = get_memory_usage()\n",
        "        logger.info(f\"Memory - GPU: {mem_usage.get('gpu_allocated', 0):.2f}GB, RAM: {mem_usage['ram_percent']:.1f}%\")\n",
        "\n",
        "    # Final evaluation on test set\n",
        "    logger.info(\"\\n📊 Final evaluation on test set...\")\n",
        "\n",
        "    # Load best model\n",
        "    checkpoint = torch.load(os.path.join(config.OUTPUT_DIR, 'models', 'best_model.pt'))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    if ema and checkpoint['ema_state_dict']:\n",
        "        ema.shadow = checkpoint['ema_state_dict']\n",
        "\n",
        "    test_losses = evaluate(model, test_loader, criterion, device, ema)\n",
        "\n",
        "    logger.info(f\"\\nTest Results:\")\n",
        "    logger.info(f\"  Total Loss: {test_losses['total']:.4f}\")\n",
        "    logger.info(f\"  MSE: {test_losses['mse']:.4f}\")\n",
        "    logger.info(f\"  R²: {test_losses['r2']:.4f}\")\n",
        "    logger.info(f\"  Correlation: {test_losses['correlation']:.4f}\")\n",
        "\n",
        "    # Save final results\n",
        "    results = {\n",
        "        'config': config.__dict__,\n",
        "        'history': dict(history),\n",
        "        'test_results': test_losses,\n",
        "        'best_epoch': checkpoint['epoch']\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(config.OUTPUT_DIR, 'results.json'), 'w') as f:\n",
        "        json.dump(results, f, indent=2, default=lambda x: float(x) if isinstance(x, np.floating) else x)\n",
        "\n",
        "    # Create summary plot\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # Loss curves\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(history['train_total'], label='Train')\n",
        "    plt.plot(history['val_total'], label='Val')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Total Loss')\n",
        "    plt.title('Training Progress')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # R² curve\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(history['val_r2'])\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('R²')\n",
        "    plt.title('Validation R² Score')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Learning rate\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(history['lr'])\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Learning Rate')\n",
        "    plt.title('Learning Rate Schedule')\n",
        "    plt.yscale('log')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Component losses\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(history['val_primary'], label='Primary')\n",
        "    plt.plot(history['val_freq'], label='Frequency')\n",
        "    plt.plot(history['val_phase'], label='Phase')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Component Losses')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.OUTPUT_DIR, 'training_summary.png'), dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "    logger.info(f\"\\n✅ Training completed! Results saved to {config.OUTPUT_DIR}\")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Main Execution\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function.\"\"\"\n",
        "    # Initialize configuration\n",
        "    config = ResearchConfig()\n",
        "\n",
        "    # Train model\n",
        "    model, history = train_research_model(config)\n",
        "\n",
        "    # Create animation from epoch visualizations\n",
        "    create_training_animation(config)\n",
        "\n",
        "def create_training_animation(config):\n",
        "    \"\"\"Create animation from epoch visualizations.\"\"\"\n",
        "    import glob\n",
        "    from PIL import Image\n",
        "\n",
        "    viz_files = sorted(glob.glob(os.path.join(config.OUTPUT_DIR, 'epoch_viz', '*.png')))\n",
        "\n",
        "    if viz_files:\n",
        "        images = [Image.open(f) for f in viz_files]\n",
        "\n",
        "        # Save as GIF\n",
        "        images[0].save(\n",
        "            os.path.join(config.OUTPUT_DIR, 'training_progress.gif'),\n",
        "            save_all=True,\n",
        "            append_images=images[1:],\n",
        "            duration=500,\n",
        "            loop=0\n",
        "        )\n",
        "\n",
        "        logger.info(\"Created training animation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYjpI393GBjp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}