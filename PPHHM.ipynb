{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**V1**"
      ],
      "metadata": {
        "id": "oK0IryYDt2uV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ItaCry_Vq3Ty"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "# from sklearn.metrics import mean_squared_error, r2_score\n",
        "# from scipy import signal\n",
        "# import warnings\n",
        "# from tqdm import tqdm\n",
        "# import time\n",
        "# import math\n",
        "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "# from scipy.signal import butter, sosfilt, sosfiltfilt, hilbert\n",
        "# import networkx as nx\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.cluster import KMeans\n",
        "# from torch.optim.swa_utils import AveragedModel, update_bn\n",
        "# from collections import defaultdict\n",
        "# import traceback\n",
        "# import json\n",
        "# import seaborn as sns\n",
        "# from datetime import datetime\n",
        "\n",
        "# # Suppress warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# # Check for GPU\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# print(f\"Using device: {device}\")\n",
        "\n",
        "# # Set random seed for reproducibility\n",
        "# SEED = 42\n",
        "# np.random.seed(SEED)\n",
        "# torch.manual_seed(SEED)\n",
        "# if torch.cuda.is_available():\n",
        "#     torch.cuda.manual_seed_all(SEED)\n",
        "#     torch.backends.cudnn.deterministic = True\n",
        "#     torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# #----------------------------------------------------------------------\n",
        "# # Enhanced Configuration for Biologically Plausible Single Reservoir\n",
        "# #----------------------------------------------------------------------\n",
        "\n",
        "# class Config:\n",
        "#     def __init__(self):\n",
        "#         # Data parameters\n",
        "#         self.NUM_ELECTRODES = 30\n",
        "#         self.CONTEXT_SIZE = 100\n",
        "#         self.PREDICT_SIZE = 50\n",
        "#         self.WINDOW_SIZE = self.CONTEXT_SIZE + self.PREDICT_SIZE\n",
        "#         self.SAMPLING_RATE = 1000\n",
        "#         self.MAX_SEQUENCES = 500  # Increased for better training\n",
        "#         self.BATCH_SIZE = 32\n",
        "#         self.STRIDE = 25  # More overlap for better learning\n",
        "\n",
        "#         # Enhanced gamma frequency bands (biologically relevant)\n",
        "#         self.FREQ_BANDS = [\n",
        "#             (30, 50),       # Low Gamma\n",
        "#             (50, 80),       # Mid Gamma\n",
        "#             (80, 120),      # High Gamma\n",
        "#             (120, 200),     # Very High Gamma\n",
        "#         ]\n",
        "\n",
        "#         # Learning parameters\n",
        "#         self.LEARNING_RATE = 1e-3  # Higher initial LR\n",
        "#         self.WEIGHT_DECAY = 1e-5\n",
        "#         self.EPOCHS = 100  # More epochs for better convergence\n",
        "#         self.PATIENCE = 20\n",
        "#         self.CLIP_GRAD_NORM = 1.0\n",
        "#         self.LR_WARMUP_EPOCHS = 5\n",
        "#         self.GRADIENT_ACCUMULATION_STEPS = 1\n",
        "\n",
        "#         # Single Biologically Plausible Reservoir parameters\n",
        "#         self.RESERVOIR_SIZE = 1000  # Single large reservoir\n",
        "#         self.SPECTRAL_RADIUS = 0.95  # Edge of stability\n",
        "#         self.LEAKY_RATE = 0.3  # Biologically plausible leak rate\n",
        "#         self.CONNECTIVITY = 0.1  # Sparse connectivity (10%)\n",
        "#         self.INPUT_SCALING = 0.5\n",
        "#         self.NOISE_LEVEL = 0.01\n",
        "#         self.ACTIVATION_FUNC = 'tanh'  # Biologically plausible activation\n",
        "\n",
        "#         # Multi-Perspective Learning Parameters\n",
        "#         self.ELECTRODE_PERSPECTIVE_DIM = 128\n",
        "#         self.COMMON_SPACE_DIM = 256\n",
        "#         self.PERSPECTIVE_ATTENTION_HEADS = 8\n",
        "#         self.USE_CROSS_ELECTRODE_ATTENTION = True\n",
        "\n",
        "#         # Network architecture parameters\n",
        "#         self.HIDDEN_SIZE = 256  # Increased for better capacity\n",
        "#         self.READOUT_HIDDEN = 512\n",
        "#         self.READOUT_LAYERS = 3\n",
        "#         self.DROPOUT = 0.2\n",
        "#         self.USE_ATTENTION = True\n",
        "#         self.ATTENTION_HEADS = 8\n",
        "#         self.USE_SKIP_CONNECTIONS = True\n",
        "#         self.USE_LAYER_NORM = True\n",
        "\n",
        "#         # Enhanced Loss Weights (crucial for good reconstruction)\n",
        "#         self.PRIMARY_LOSS_WEIGHT = 1.0\n",
        "#         self.RECONSTRUCTION_LOSS_WEIGHT = 0.5  # Increased\n",
        "#         self.CONSISTENCY_LOSS_WEIGHT = 0.2\n",
        "#         self.DIVERSITY_LOSS_WEIGHT = 0.1\n",
        "#         self.FREQUENCY_LOSS_WEIGHT = 0.3       # Added frequency domain loss\n",
        "#         self.SMOOTHNESS_LOSS_WEIGHT = 0.1      # Added for temporal smoothness\n",
        "\n",
        "#         # Training strategies\n",
        "#         self.USE_SWA = True\n",
        "#         self.SWA_START = 50\n",
        "#         self.USE_CURRICULUM = True\n",
        "\n",
        "#         # Visualization parameters\n",
        "#         self.VISUALIZE_EVERY_N_EPOCHS = 5\n",
        "#         self.NUM_SAMPLES_TO_VISUALIZE = 5\n",
        "\n",
        "#         # Directory setup\n",
        "#         self.OUTPUT_DIR = \"enhanced_single_reservoir_results\"\n",
        "#         self.create_directories()\n",
        "\n",
        "#     def create_directories(self):\n",
        "#         \"\"\"Create necessary directories for outputs.\"\"\"\n",
        "#         os.makedirs(self.OUTPUT_DIR, exist_ok=True)\n",
        "#         for subdir in ['models', 'analysis', 'logs', 'reconstructions', 'electrode_perspectives']:\n",
        "#             os.makedirs(os.path.join(self.OUTPUT_DIR, subdir), exist_ok=True)\n",
        "\n",
        "# # Initialize configuration\n",
        "# config = Config()\n",
        "\n",
        "# #----------------------------------------------------------------------\n",
        "# # Data Loading Functions (Keep Original)\n",
        "# #----------------------------------------------------------------------\n",
        "\n",
        "# def find_data_file(path, filename):\n",
        "#     \"\"\"Find the specified data file in the given path or its subdirectories.\"\"\"\n",
        "#     data_file = os.path.join(path, filename)\n",
        "#     if os.path.exists(data_file):\n",
        "#         return data_file\n",
        "\n",
        "#     for root, dirs, files in os.walk(path):\n",
        "#         if filename in files:\n",
        "#             return os.path.join(root, filename)\n",
        "\n",
        "#     raise FileNotFoundError(f\"Could not find {filename} in {path}\")\n",
        "\n",
        "# def load_electrode_positions(path):\n",
        "#     \"\"\"Load electrode position data from CSV file.\"\"\"\n",
        "#     print(\"Loading electrode positions...\")\n",
        "#     positions_file = find_data_file(path, 'limbic_insular_probe_channels.csv')\n",
        "\n",
        "#     positions = pd.read_csv(positions_file)\n",
        "#     positions = positions.rename(columns={\n",
        "#         'channel_index': 'channel_num',\n",
        "#         'probe_horizontal_position': 'x_position',\n",
        "#         'probe_vertical_position': 'y_position'\n",
        "#     })\n",
        "\n",
        "#     print(f\"Loaded positions for {len(positions)} electrodes\")\n",
        "#     return positions\n",
        "\n",
        "# def select_electrodes_fixed(positions, num_electrodes=None):\n",
        "#     \"\"\"Select electrodes using KMeans clustering for optimal spatial coverage.\"\"\"\n",
        "#     if num_electrodes is None:\n",
        "#         num_electrodes = config.NUM_ELECTRODES\n",
        "\n",
        "#     num_electrodes = min(num_electrodes, len(positions))\n",
        "#     print(f\"Selecting {num_electrodes} electrodes for analysis...\")\n",
        "\n",
        "#     if num_electrodes == len(positions):\n",
        "#         selected_indices = list(range(len(positions)))\n",
        "#         channel_nums = positions['channel_num'].astype(int).values\n",
        "#         return channel_nums, selected_indices\n",
        "\n",
        "#     # Normalize positions for clustering\n",
        "#     x_norm = (positions['x_position'] - positions['x_position'].min()) / (positions['x_position'].max() - positions['x_position'].min())\n",
        "#     y_norm = (positions['y_position'] - positions['y_position'].min()) / (positions['y_position'].max() - positions['y_position'].min())\n",
        "#     coords = np.column_stack((x_norm.values, y_norm.values))\n",
        "\n",
        "#     # Use KMeans to select representative electrodes\n",
        "#     kmeans = KMeans(n_clusters=num_electrodes, random_state=SEED, n_init=10)\n",
        "#     kmeans.fit(coords)\n",
        "\n",
        "#     # Select the electrode closest to each cluster center\n",
        "#     selected_indices = []\n",
        "#     for cluster_idx in range(num_electrodes):\n",
        "#         cluster_points = np.where(kmeans.labels_ == cluster_idx)[0]\n",
        "\n",
        "#         if len(cluster_points) > 0:\n",
        "#             center = kmeans.cluster_centers_[cluster_idx]\n",
        "#             distances = np.sqrt(np.sum((coords[cluster_points] - center)**2, axis=1))\n",
        "#             closest_idx = cluster_points[np.argmin(distances)]\n",
        "#         else:\n",
        "#             center = kmeans.cluster_centers_[cluster_idx]\n",
        "#             all_distances = np.sqrt(np.sum((coords - center)**2, axis=1))\n",
        "#             closest_idx = np.argmin(all_distances)\n",
        "\n",
        "#         selected_indices.append(closest_idx)\n",
        "\n",
        "#     channel_nums = positions.iloc[selected_indices]['channel_num'].astype(int).values\n",
        "#     print(f\"Selected {len(channel_nums)} electrodes with good spatial coverage\")\n",
        "#     return channel_nums, selected_indices\n",
        "\n",
        "# def load_lfp_data(path, channel_nums, max_rows=500000):\n",
        "#     \"\"\"Load LFP data from CSV file.\"\"\"\n",
        "#     print(f\"Loading LFP data for {len(channel_nums)} channels...\")\n",
        "#     data_file = find_data_file(path, 'limbic_insular_ieeg_data (7).csv')\n",
        "\n",
        "#     cols_to_use = ['timestamp', 'presentation_id'] + [f'channel_{ch}' for ch in channel_nums]\n",
        "#     print(f\"Loading columns: {cols_to_use[:5]}... (and {len(cols_to_use)-5} more)\")\n",
        "\n",
        "#     data = pd.read_csv(data_file, usecols=cols_to_use, nrows=max_rows)\n",
        "#     print(f\"Loaded {len(data)} rows of LFP data\")\n",
        "\n",
        "#     num_presentations = data['presentation_id'].nunique()\n",
        "#     print(f\"Data contains {num_presentations} unique presentation_ids\")\n",
        "\n",
        "#     return data\n",
        "\n",
        "# def extract_windows(data, context_size=None, predict_size=None, stride=None, max_windows=None):\n",
        "#     \"\"\"Extract time windows from continuous data for training and prediction.\"\"\"\n",
        "#     if context_size is None:\n",
        "#         context_size = config.CONTEXT_SIZE\n",
        "#     if predict_size is None:\n",
        "#         predict_size = config.PREDICT_SIZE\n",
        "#     if stride is None:\n",
        "#         stride = config.STRIDE\n",
        "#     if max_windows is None:\n",
        "#         max_windows = config.MAX_SEQUENCES\n",
        "\n",
        "#     print(f\"Extracting windows with context={context_size}, predict={predict_size}, stride={stride}\")\n",
        "\n",
        "#     use_presentation_id = 'presentation_id' in data.columns\n",
        "#     if use_presentation_id:\n",
        "#         print(f\"Using presentation_id to ensure windows come from same presentation\")\n",
        "\n",
        "#     data_cols = [col for col in data.columns if col.startswith('channel_')]\n",
        "#     window_size = context_size + predict_size\n",
        "#     windows = []\n",
        "\n",
        "#     if use_presentation_id:\n",
        "#         presentation_groups = data.groupby('presentation_id')\n",
        "\n",
        "#         for presentation_id, group in presentation_groups:\n",
        "#             if len(group) < window_size:\n",
        "#                 continue\n",
        "\n",
        "#             presentation_data = group[data_cols].values\n",
        "\n",
        "#             for start in range(0, len(presentation_data) - window_size + 1, stride):\n",
        "#                 if len(windows) >= max_windows:\n",
        "#                     break\n",
        "\n",
        "#                 window = presentation_data[start:start + window_size]\n",
        "#                 if np.isnan(window).any():\n",
        "#                     continue\n",
        "\n",
        "#                 windows.append(window)\n",
        "\n",
        "#             if len(windows) >= max_windows:\n",
        "#                 break\n",
        "#     else:\n",
        "#         data_values = data[data_cols].values\n",
        "\n",
        "#         for start in range(0, len(data_values) - window_size, stride):\n",
        "#             if len(windows) >= max_windows:\n",
        "#                 break\n",
        "\n",
        "#             window = data_values[start:start + window_size]\n",
        "#             if np.isnan(window).any():\n",
        "#                 continue\n",
        "\n",
        "#             windows.append(window)\n",
        "\n",
        "#     windows = np.array(windows)\n",
        "#     print(f\"Extracted {len(windows)} windows with shape: {windows.shape}\")\n",
        "#     return windows\n",
        "\n",
        "# #----------------------------------------------------------------------\n",
        "# # Enhanced Preprocessing with Better Scaling\n",
        "# #----------------------------------------------------------------------\n",
        "\n",
        "# def create_filter_bank(fs, freq_bands):\n",
        "#     \"\"\"Create filter bank for frequency decomposition.\"\"\"\n",
        "#     filter_bank = []\n",
        "#     nyquist = fs / 2.0\n",
        "\n",
        "#     for band_idx, (low_freq, high_freq) in enumerate(freq_bands):\n",
        "#         low = low_freq / nyquist\n",
        "#         high = high_freq / nyquist\n",
        "#         sos = signal.butter(4, [low, high], btype='bandpass', output='sos')\n",
        "#         filter_bank.append((sos, band_idx, (low_freq, high_freq)))\n",
        "\n",
        "#     return filter_bank\n",
        "\n",
        "# def extract_frequency_features(windows, fs=None, freq_bands=None):\n",
        "#     \"\"\"Extract frequency band features.\"\"\"\n",
        "#     if fs is None:\n",
        "#         fs = config.SAMPLING_RATE\n",
        "#     if freq_bands is None:\n",
        "#         freq_bands = config.FREQ_BANDS\n",
        "\n",
        "#     print(\"Extracting frequency band features...\")\n",
        "#     n_samples, window_size, n_channels = windows.shape\n",
        "#     n_bands = len(freq_bands)\n",
        "\n",
        "#     filter_bank = create_filter_bank(fs, freq_bands)\n",
        "#     band_powers = np.zeros((n_samples, n_bands, n_channels))\n",
        "\n",
        "#     for (sos, band_idx, (low_freq, high_freq)) in filter_bank:\n",
        "#         print(f\"Processing band {band_idx+1}/{n_bands}: {low_freq}-{high_freq} Hz\")\n",
        "\n",
        "#         for i in tqdm(range(n_samples), desc=f\"Band {band_idx+1}\"):\n",
        "#             for j in range(n_channels):\n",
        "#                 signal_i = windows[i, :, j]\n",
        "#                 filtered = signal.sosfiltfilt(sos, signal_i)\n",
        "#                 # Compute band power\n",
        "#                 band_powers[i, band_idx, j] = np.mean(filtered**2)\n",
        "\n",
        "#     return band_powers\n",
        "\n",
        "# def preprocess_data(windows, context_size=None, predict_size=None):\n",
        "#     \"\"\"Enhanced preprocessing with better normalization.\"\"\"\n",
        "#     if context_size is None:\n",
        "#         context_size = config.CONTEXT_SIZE\n",
        "#     if predict_size is None:\n",
        "#         predict_size = config.PREDICT_SIZE\n",
        "\n",
        "#     print(\"Preprocessing data...\")\n",
        "#     num_windows, window_size, num_electrodes = windows.shape\n",
        "\n",
        "#     context_windows = windows[:, :context_size, :]\n",
        "#     target_windows = windows[:, context_size:, :]\n",
        "\n",
        "#     # Better scaling strategy\n",
        "#     scaler = StandardScaler()  # Changed from RobustScaler\n",
        "\n",
        "#     # Scale to microvolts first\n",
        "#     context_flat = context_windows.reshape(-1, num_electrodes) * 1e6\n",
        "#     target_flat = target_windows.reshape(-1, num_electrodes) * 1e6\n",
        "\n",
        "#     # Fit scaler on all data\n",
        "#     all_data = np.vstack([context_flat, target_flat])\n",
        "#     scaler.fit(all_data)\n",
        "\n",
        "#     # Transform data\n",
        "#     context_scaled = scaler.transform(context_flat).reshape(context_windows.shape)\n",
        "#     target_scaled = scaler.transform(target_flat).reshape(target_windows.shape)\n",
        "\n",
        "#     # Extract frequency features for context\n",
        "#     band_powers = extract_frequency_features(context_windows * 1e6, config.SAMPLING_RATE, config.FREQ_BANDS)\n",
        "\n",
        "#     # Create dataset\n",
        "#     X_data = {\n",
        "#         'raw': context_scaled,\n",
        "#         'band_powers': band_powers\n",
        "#     }\n",
        "\n",
        "#     y_data = target_scaled\n",
        "\n",
        "#     # Split data\n",
        "#     indices = np.arange(len(context_scaled))\n",
        "#     train_idx, temp_idx = train_test_split(indices, test_size=0.3, random_state=SEED)\n",
        "#     val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=SEED)\n",
        "\n",
        "#     # Create datasets\n",
        "#     train_dataset = LFPDataset(\n",
        "#         {k: v[train_idx] for k, v in X_data.items()},\n",
        "#         y_data[train_idx]\n",
        "#     )\n",
        "\n",
        "#     val_dataset = LFPDataset(\n",
        "#         {k: v[val_idx] for k, v in X_data.items()},\n",
        "#         y_data[val_idx]\n",
        "#     )\n",
        "\n",
        "#     test_dataset = LFPDataset(\n",
        "#         {k: v[test_idx] for k, v in X_data.items()},\n",
        "#         y_data[test_idx]\n",
        "#     )\n",
        "\n",
        "#     # Create data loaders\n",
        "#     train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "#     val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False)\n",
        "#     test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "#     print(f\"Created data loaders with {len(train_loader)} training batches\")\n",
        "\n",
        "#     return train_loader, val_loader, test_loader, scaler\n",
        "\n",
        "# class LFPDataset(Dataset):\n",
        "#     \"\"\"Dataset for LFP data.\"\"\"\n",
        "#     def __init__(self, X, y):\n",
        "#         self.X_raw = torch.FloatTensor(X['raw'])\n",
        "#         self.X_band_powers = torch.FloatTensor(X['band_powers'])\n",
        "#         self.y = torch.FloatTensor(y)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.y)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         return {\n",
        "#             'raw': self.X_raw[idx],\n",
        "#             'band_powers': self.X_band_powers[idx]\n",
        "#         }, self.y[idx]\n",
        "\n",
        "# #----------------------------------------------------------------------\n",
        "# # Biologically Plausible Single Reservoir\n",
        "# #----------------------------------------------------------------------\n",
        "\n",
        "# class BiologicallyPlausibleReservoir(nn.Module):\n",
        "#     \"\"\"Single biologically plausible reservoir with Dale's principle.\"\"\"\n",
        "\n",
        "#     def __init__(self, config):\n",
        "#         super().__init__()\n",
        "#         self.config = config\n",
        "#         self.reservoir_size = config.RESERVOIR_SIZE\n",
        "#         self.input_size = config.NUM_ELECTRODES\n",
        "#         self.leaky_rate = config.LEAKY_RATE\n",
        "\n",
        "#         # Initialize reservoir weights with biological constraints\n",
        "#         self._initialize_reservoir()\n",
        "\n",
        "#         # Input projection\n",
        "#         self.input_projection = nn.Linear(self.input_size, self.reservoir_size, bias=False)\n",
        "#         nn.init.uniform_(self.input_projection.weight, -config.INPUT_SCALING, config.INPUT_SCALING)\n",
        "\n",
        "#         # Dale's principle: separate excitatory and inhibitory neurons\n",
        "#         self.excitatory_mask = torch.rand(self.reservoir_size) < 0.8  # 80% excitatory\n",
        "#         self.inhibitory_mask = ~self.excitatory_mask\n",
        "\n",
        "#         # Activation function\n",
        "#         if config.ACTIVATION_FUNC == 'tanh':\n",
        "#             self.activation = nn.Tanh()\n",
        "#         elif config.ACTIVATION_FUNC == 'relu':\n",
        "#             self.activation = nn.ReLU()\n",
        "#         else:\n",
        "#             self.activation = nn.Tanh()\n",
        "\n",
        "#         # Layer normalization for stability\n",
        "#         self.layer_norm = nn.LayerNorm(self.reservoir_size)\n",
        "\n",
        "#         # State buffer\n",
        "#         self.register_buffer('state', None)\n",
        "\n",
        "#     def _initialize_reservoir(self):\n",
        "#         \"\"\"Initialize reservoir with biological constraints.\"\"\"\n",
        "#         # Create sparse connectivity matrix\n",
        "#         W = torch.zeros(self.reservoir_size, self.reservoir_size)\n",
        "#         num_connections = int(self.config.CONNECTIVITY * self.reservoir_size * self.reservoir_size)\n",
        "\n",
        "#         # Random connections\n",
        "#         indices = torch.randperm(self.reservoir_size * self.reservoir_size)[:num_connections]\n",
        "#         i_indices = indices // self.reservoir_size\n",
        "#         j_indices = indices % self.reservoir_size\n",
        "\n",
        "#         # Remove self-connections\n",
        "#         mask = i_indices != j_indices\n",
        "#         i_indices = i_indices[mask]\n",
        "#         j_indices = j_indices[mask]\n",
        "\n",
        "#         # Initialize weights\n",
        "#         W[i_indices, j_indices] = torch.randn(len(i_indices))\n",
        "\n",
        "#         # Apply spectral radius normalization\n",
        "#         eigenvalues = torch.linalg.eigvals(W)\n",
        "#         spectral_radius = torch.max(torch.abs(eigenvalues)).item()\n",
        "\n",
        "#         if spectral_radius > 0:\n",
        "#             W = W * (self.config.SPECTRAL_RADIUS / spectral_radius)\n",
        "\n",
        "#         self.register_buffer('W', W)\n",
        "\n",
        "#     def reset_state(self, batch_size=1):\n",
        "#         \"\"\"Reset reservoir state.\"\"\"\n",
        "#         self.state = torch.zeros(batch_size, self.reservoir_size, device=self.W.device)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         \"\"\"Forward pass through reservoir.\"\"\"\n",
        "#         batch_size = x.shape[0]\n",
        "\n",
        "#         if self.state is None or self.state.shape[0] != batch_size:\n",
        "#             self.reset_state(batch_size)\n",
        "\n",
        "#         # Input contribution\n",
        "#         input_contribution = self.input_projection(x)\n",
        "\n",
        "#         # Recurrent contribution\n",
        "#         recurrent_contribution = torch.matmul(self.state, self.W.T)\n",
        "\n",
        "#         # Apply Dale's principle (ensure positive/negative neurons)\n",
        "#         if self.excitatory_mask.device != recurrent_contribution.device:\n",
        "#             self.excitatory_mask = self.excitatory_mask.to(recurrent_contribution.device)\n",
        "#             self.inhibitory_mask = self.inhibitory_mask.to(recurrent_contribution.device)\n",
        "\n",
        "#         recurrent_contribution = torch.where(\n",
        "#             self.excitatory_mask.unsqueeze(0),\n",
        "#             torch.abs(recurrent_contribution),\n",
        "#             -torch.abs(recurrent_contribution)\n",
        "#         )\n",
        "\n",
        "#         # Combine inputs\n",
        "#         pre_activation = input_contribution + recurrent_contribution\n",
        "\n",
        "#         # Apply activation\n",
        "#         new_state = self.activation(pre_activation)\n",
        "\n",
        "#         # Leaky integration\n",
        "#         self.state = (1 - self.leaky_rate) * self.state + self.leaky_rate * new_state\n",
        "\n",
        "#         # Add small noise for regularization\n",
        "#         if self.training and self.config.NOISE_LEVEL > 0:\n",
        "#             noise = torch.randn_like(self.state) * self.config.NOISE_LEVEL\n",
        "#             self.state = self.state + noise\n",
        "\n",
        "#         # Layer normalization\n",
        "#         output = self.layer_norm(self.state)\n",
        "\n",
        "#         return output\n",
        "\n",
        "# #----------------------------------------------------------------------\n",
        "# # Enhanced Model Components\n",
        "# #----------------------------------------------------------------------\n",
        "\n",
        "# class ElectrodeAttentionModule(nn.Module):\n",
        "#     \"\"\"Electrode-specific attention for extracting perspectives.\"\"\"\n",
        "\n",
        "#     def __init__(self, reservoir_dim, electrode_dim, num_heads=4):\n",
        "#         super().__init__()\n",
        "#         self.attention = nn.MultiheadAttention(\n",
        "#             embed_dim=reservoir_dim,\n",
        "#             num_heads=num_heads,\n",
        "#             dropout=0.1,\n",
        "#             batch_first=True\n",
        "#         )\n",
        "\n",
        "#         self.projection = nn.Sequential(\n",
        "#             nn.Linear(reservoir_dim, electrode_dim),\n",
        "#             nn.LayerNorm(electrode_dim),\n",
        "#             nn.GELU(),\n",
        "#             nn.Dropout(0.1)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, reservoir_states):\n",
        "#         \"\"\"Extract electrode-specific perspective.\"\"\"\n",
        "#         # Self-attention on reservoir states\n",
        "#         attended, weights = self.attention(\n",
        "#             reservoir_states, reservoir_states, reservoir_states\n",
        "#         )\n",
        "\n",
        "#         # Project to electrode-specific space\n",
        "#         perspective = self.projection(attended)\n",
        "\n",
        "#         return perspective, weights\n",
        "\n",
        "# class TemporalProcessor(nn.Module):\n",
        "#     \"\"\"Process temporal sequences with BiLSTM.\"\"\"\n",
        "\n",
        "#     def __init__(self, input_dim, hidden_dim, num_layers=2):\n",
        "#         super().__init__()\n",
        "#         self.lstm = nn.LSTM(\n",
        "#             input_size=input_dim,\n",
        "#             hidden_size=hidden_dim,\n",
        "#             num_layers=num_layers,\n",
        "#             batch_first=True,\n",
        "#             dropout=0.2,\n",
        "#             bidirectional=True\n",
        "#         )\n",
        "\n",
        "#         self.projection = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         \"\"\"Process temporal sequence.\"\"\"\n",
        "#         output, (h_n, c_n) = self.lstm(x)\n",
        "\n",
        "#         # Combine bidirectional outputs\n",
        "#         output = self.projection(output)\n",
        "\n",
        "#         # Get final hidden state\n",
        "#         h_forward = h_n[-2, :, :]\n",
        "#         h_backward = h_n[-1, :, :]\n",
        "#         final_hidden = torch.cat([h_forward, h_backward], dim=1)\n",
        "#         final_hidden = self.projection(final_hidden)\n",
        "\n",
        "#         return output, final_hidden\n",
        "\n",
        "# class SignalDecoder(nn.Module):\n",
        "#     \"\"\"Decode to reconstruct signals with skip connections.\"\"\"\n",
        "\n",
        "#     def __init__(self, input_dim, output_dim, hidden_dims=[512, 256, 128]):\n",
        "#         super().__init__()\n",
        "\n",
        "#         layers = []\n",
        "#         prev_dim = input_dim\n",
        "\n",
        "#         for hidden_dim in hidden_dims:\n",
        "#             layers.extend([\n",
        "#                 nn.Linear(prev_dim, hidden_dim),\n",
        "#                 nn.LayerNorm(hidden_dim),\n",
        "#                 nn.GELU(),\n",
        "#                 nn.Dropout(0.1)\n",
        "#             ])\n",
        "#             prev_dim = hidden_dim\n",
        "\n",
        "#         layers.append(nn.Linear(prev_dim, output_dim))\n",
        "\n",
        "#         self.decoder = nn.Sequential(*layers)\n",
        "\n",
        "#         # Skip connection if dimensions match\n",
        "#         self.use_skip = (input_dim == output_dim)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         \"\"\"Decode with skip connection.\"\"\"\n",
        "#         output = self.decoder(x)\n",
        "\n",
        "#         if self.use_skip and x.shape == output.shape:\n",
        "#             output = output + 0.1 * x  # Residual connection\n",
        "\n",
        "#         return output\n",
        "\n",
        "# #----------------------------------------------------------------------\n",
        "# # Main Model with Single Reservoir\n",
        "# #----------------------------------------------------------------------\n",
        "\n",
        "# class EnhancedSingleReservoirESN(nn.Module):\n",
        "#     \"\"\"Enhanced ESN with single reservoir and multi-perspective learning.\"\"\"\n",
        "\n",
        "#     def __init__(self, config):\n",
        "#         super().__init__()\n",
        "#         self.config = config\n",
        "#         self.num_electrodes = config.NUM_ELECTRODES\n",
        "#         self.num_freq_bands = len(config.FREQ_BANDS)\n",
        "#         self.predict_size = config.PREDICT_SIZE\n",
        "\n",
        "#         # Feature extraction\n",
        "#         self.feature_extractor = nn.Sequential(\n",
        "#             nn.Linear(self.num_electrodes + self.num_freq_bands * self.num_electrodes,\n",
        "#                      config.HIDDEN_SIZE),\n",
        "#             nn.LayerNorm(config.HIDDEN_SIZE),\n",
        "#             nn.GELU(),\n",
        "#             nn.Dropout(config.DROPOUT)\n",
        "#         )\n",
        "\n",
        "#         # Single biologically plausible reservoir\n",
        "#         self.reservoir = BiologicallyPlausibleReservoir(config)\n",
        "\n",
        "#         # Electrode-specific attention modules\n",
        "#         self.electrode_attentions = nn.ModuleList([\n",
        "#             ElectrodeAttentionModule(\n",
        "#                 reservoir_dim=config.RESERVOIR_SIZE,\n",
        "#                 electrode_dim=config.ELECTRODE_PERSPECTIVE_DIM,\n",
        "#                 num_heads=config.PERSPECTIVE_ATTENTION_HEADS\n",
        "#             ) for _ in range(self.num_electrodes)\n",
        "#         ])\n",
        "\n",
        "#         # Temporal processor\n",
        "#         self.temporal_processor = TemporalProcessor(\n",
        "#             input_dim=config.RESERVOIR_SIZE,\n",
        "#             hidden_dim=config.READOUT_HIDDEN,\n",
        "#             num_layers=2\n",
        "#         )\n",
        "\n",
        "#         # Prediction decoders for each timestep\n",
        "#         self.decoders = nn.ModuleList([\n",
        "#             SignalDecoder(\n",
        "#                 input_dim=config.READOUT_HIDDEN,\n",
        "#                 output_dim=self.num_electrodes,\n",
        "#                 hidden_dims=[config.READOUT_HIDDEN, config.READOUT_HIDDEN // 2]\n",
        "#             ) for _ in range(config.PREDICT_SIZE)\n",
        "#         ])\n",
        "\n",
        "#         # Reconstruction decoder for auxiliary task\n",
        "#         self.reconstruction_decoder = SignalDecoder(\n",
        "#             input_dim=config.ELECTRODE_PERSPECTIVE_DIM * self.num_electrodes,\n",
        "#             output_dim=self.num_electrodes * config.CONTEXT_SIZE,\n",
        "#             hidden_dims=[512, 256]\n",
        "#         )\n",
        "\n",
        "#     def reset_states(self):\n",
        "#         \"\"\"Reset all states.\"\"\"\n",
        "#         self.reservoir.reset_state()\n",
        "\n",
        "#     def forward(self, x_dict, return_perspectives=False):\n",
        "#         \"\"\"Forward pass with optional perspective extraction.\"\"\"\n",
        "#         x_raw = x_dict['raw']\n",
        "#         x_band_powers = x_dict['band_powers']\n",
        "\n",
        "#         batch_size, context_size, num_electrodes = x_raw.shape\n",
        "#         device = x_raw.device\n",
        "\n",
        "#         self.reset_states()\n",
        "\n",
        "#         # Storage for analysis\n",
        "#         reservoir_states = []\n",
        "#         electrode_perspectives = []\n",
        "\n",
        "#         # Process sequence through reservoir\n",
        "#         for t in range(context_size):\n",
        "#             # Extract features at time t\n",
        "#             raw_t = x_raw[:, t, :]\n",
        "#             band_powers_t = x_band_powers[:, :, :].reshape(batch_size, -1)  # Flatten band powers\n",
        "\n",
        "#             # Combine features\n",
        "#             features = torch.cat([raw_t, band_powers_t], dim=1)\n",
        "#             features = self.feature_extractor(features)\n",
        "\n",
        "#             # Process through reservoir\n",
        "#             reservoir_state = self.reservoir(raw_t)  # Use raw signal for reservoir input\n",
        "#             reservoir_states.append(reservoir_state)\n",
        "\n",
        "#         # Stack reservoir states\n",
        "#         reservoir_sequence = torch.stack(reservoir_states, dim=1)  # [batch, time, reservoir_size]\n",
        "\n",
        "#         # Extract electrode perspectives if requested\n",
        "#         if return_perspectives:\n",
        "#             for e_idx in range(self.num_electrodes):\n",
        "#                 perspective, _ = self.electrode_attentions[e_idx](reservoir_sequence)\n",
        "#                 # Average over time for stable perspective\n",
        "#                 perspective_avg = perspective.mean(dim=1)\n",
        "#                 electrode_perspectives.append(perspective_avg)\n",
        "\n",
        "#         # Temporal processing\n",
        "#         temporal_output, final_hidden = self.temporal_processor(reservoir_sequence)\n",
        "\n",
        "#         # Generate predictions for each future timestep\n",
        "#         predictions = []\n",
        "#         current_hidden = final_hidden\n",
        "\n",
        "#         for t in range(self.predict_size):\n",
        "#             # Decode current hidden state\n",
        "#             pred_t = self.decoders[t](current_hidden)\n",
        "#             predictions.append(pred_t)\n",
        "\n",
        "#             # Update hidden state (autoregressive)\n",
        "#             if t < self.predict_size - 1:\n",
        "#                 # Simple update rule\n",
        "#                 current_hidden = current_hidden * 0.9 + 0.1 * self.decoders[t].decoder[0](current_hidden)\n",
        "\n",
        "#         # Stack predictions\n",
        "#         predictions = torch.stack(predictions, dim=1)  # [batch, predict_size, num_electrodes]\n",
        "\n",
        "#         if return_perspectives:\n",
        "#             # Reconstruction task\n",
        "#             all_perspectives = torch.cat(electrode_perspectives, dim=1)\n",
        "#             reconstruction = self.reconstruction_decoder(all_perspectives)\n",
        "#             reconstruction = reconstruction.view(batch_size, context_size, num_electrodes)\n",
        "\n",
        "#             return predictions, {\n",
        "#                 'perspectives': electrode_perspectives,\n",
        "#                 'reconstruction': reconstruction,\n",
        "#                 'reservoir_states': reservoir_sequence\n",
        "#             }\n",
        "#         else:\n",
        "#             return predictions\n",
        "\n",
        "# #----------------------------------------------------------------------\n",
        "# # Enhanced Loss Functions\n",
        "# #----------------------------------------------------------------------\n",
        "\n",
        "# class ComprehensiveLoss(nn.Module):\n",
        "#     \"\"\"Comprehensive loss function for signal reconstruction.\"\"\"\n",
        "\n",
        "#     def __init__(self, config):\n",
        "#         super().__init__()\n",
        "#         self.config = config\n",
        "#         self.mse = nn.MSELoss()\n",
        "#         self.smooth_l1 = nn.SmoothL1Loss()\n",
        "\n",
        "#     def frequency_loss(self, pred, target, sampling_rate=1000):\n",
        "#         \"\"\"Compute loss in frequency domain.\"\"\"\n",
        "#         # Compute FFT\n",
        "#         pred_fft = torch.fft.rfft(pred, dim=1)\n",
        "#         target_fft = torch.fft.rfft(target, dim=1)\n",
        "\n",
        "#         # Magnitude spectrum\n",
        "#         pred_mag = torch.abs(pred_fft)\n",
        "#         target_mag = torch.abs(target_fft)\n",
        "\n",
        "#         # Focus on gamma frequencies\n",
        "#         freq_bins = pred_mag.shape[1]\n",
        "#         gamma_start = int(30 * freq_bins / (sampling_rate / 2))\n",
        "#         gamma_end = int(200 * freq_bins / (sampling_rate / 2))\n",
        "\n",
        "#         # Weighted frequency loss\n",
        "#         freq_loss = self.mse(pred_mag[:, gamma_start:gamma_end],\n",
        "#                             target_mag[:, gamma_start:gamma_end])\n",
        "\n",
        "#         return freq_loss\n",
        "\n",
        "#     def smoothness_loss(self, pred):\n",
        "#         \"\"\"Temporal smoothness loss.\"\"\"\n",
        "#         # First-order differences\n",
        "#         diff1 = pred[:, 1:, :] - pred[:, :-1, :]\n",
        "#         smooth_loss = torch.mean(diff1**2)\n",
        "\n",
        "#         return smooth_loss\n",
        "\n",
        "#     def forward(self, predictions, targets, aux_outputs=None):\n",
        "#         \"\"\"Compute comprehensive loss.\"\"\"\n",
        "#         # Primary prediction loss\n",
        "#         primary_loss = self.mse(predictions, targets)\n",
        "\n",
        "#         # Frequency domain loss\n",
        "#         freq_loss = 0\n",
        "#         for e in range(predictions.shape[2]):  # For each electrode\n",
        "#             freq_loss += self.frequency_loss(predictions[:, :, e], targets[:, :, e])\n",
        "#         freq_loss /= predictions.shape[2]\n",
        "\n",
        "#         # Smoothness loss\n",
        "#         smooth_loss = self.smoothness_loss(predictions)\n",
        "\n",
        "#         # Total loss\n",
        "#         total_loss = (\n",
        "#             self.config.PRIMARY_LOSS_WEIGHT * primary_loss +\n",
        "#             self.config.FREQUENCY_LOSS_WEIGHT * freq_loss +\n",
        "#             self.config.SMOOTHNESS_LOSS_WEIGHT * smooth_loss\n",
        "#         )\n",
        "\n",
        "#         # Add reconstruction loss if available\n",
        "#         if aux_outputs is not None and 'reconstruction' in aux_outputs:\n",
        "#             reconstruction = aux_outputs['reconstruction']\n",
        "#             # Get corresponding input for reconstruction loss\n",
        "#             batch_size = predictions.shape[0]\n",
        "#             context_size = reconstruction.shape[1]\n",
        "\n",
        "#             # Note: We need the input data for reconstruction loss\n",
        "#             # This should be passed from the training loop\n",
        "#             if 'input_data' in aux_outputs:\n",
        "#                 input_data = aux_outputs['input_data']\n",
        "#                 recon_loss = self.mse(reconstruction, input_data)\n",
        "#                 total_loss += self.config.RECONSTRUCTION_LOSS_WEIGHT * recon_loss\n",
        "#             else:\n",
        "#                 recon_loss = torch.tensor(0.0, device=predictions.device)\n",
        "#         else:\n",
        "#             recon_loss = torch.tensor(0.0, device=predictions.device)\n",
        "\n",
        "#         return {\n",
        "#             'total_loss': total_loss,\n",
        "#             'primary_loss': primary_loss,\n",
        "#             'freq_loss': freq_loss,\n",
        "#             'smooth_loss': smooth_loss,\n",
        "#             'recon_loss': recon_loss\n",
        "#         }\n",
        "\n",
        "# #----------------------------------------------------------------------\n",
        "# # Visualization Functions\n",
        "# #----------------------------------------------------------------------\n",
        "\n",
        "# def visualize_reconstructions(model, data_loader, scaler, epoch, save_dir, num_samples=5):\n",
        "#     \"\"\"Visualize signal reconstructions.\"\"\"\n",
        "#     model.eval()\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         # Get a batch of data\n",
        "#         inputs, targets = next(iter(data_loader))\n",
        "#         inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "#         targets = targets.to(device)\n",
        "\n",
        "#         # Get predictions\n",
        "#         predictions, aux_outputs = model(inputs, return_perspectives=True)\n",
        "\n",
        "#         # Convert to numpy\n",
        "#         inputs_np = inputs['raw'].cpu().numpy()\n",
        "#         targets_np = targets.cpu().numpy()\n",
        "#         predictions_np = predictions.cpu().numpy()\n",
        "#         reconstruction_np = aux_outputs['reconstruction'].cpu().numpy()\n",
        "\n",
        "#         # Inverse transform\n",
        "#         batch_size, context_size, num_electrodes = inputs_np.shape\n",
        "#         _, predict_size, _ = predictions_np.shape\n",
        "\n",
        "#         # Reshape for inverse transform\n",
        "#         inputs_reshaped = inputs_np.reshape(-1, num_electrodes)\n",
        "#         targets_reshaped = targets_np.reshape(-1, num_electrodes)\n",
        "#         predictions_reshaped = predictions_np.reshape(-1, num_electrodes)\n",
        "#         reconstruction_reshaped = reconstruction_np.reshape(-1, num_electrodes)\n",
        "\n",
        "#         # Inverse transform\n",
        "#         inputs_orig = scaler.inverse_transform(inputs_reshaped).reshape(batch_size, context_size, num_electrodes)\n",
        "#         targets_orig = scaler.inverse_transform(targets_reshaped).reshape(batch_size, predict_size, num_electrodes)\n",
        "#         predictions_orig = scaler.inverse_transform(predictions_reshaped).reshape(batch_size, predict_size, num_electrodes)\n",
        "#         reconstruction_orig = scaler.inverse_transform(reconstruction_reshaped).reshape(batch_size, context_size, num_electrodes)\n",
        "\n",
        "#         # Create figure\n",
        "#         fig, axes = plt.subplots(num_samples, 3, figsize=(20, 4*num_samples))\n",
        "#         if num_samples == 1:\n",
        "#             axes = axes.reshape(1, -1)\n",
        "\n",
        "#         for sample_idx in range(min(num_samples, batch_size)):\n",
        "#             # Select electrodes to visualize\n",
        "#             electrode_indices = [0, num_electrodes//2, num_electrodes-1]\n",
        "\n",
        "#             for e_idx, electrode in enumerate(electrode_indices):\n",
        "#                 ax = axes[sample_idx, e_idx]\n",
        "\n",
        "#                 # Context (input)\n",
        "#                 context_signal = inputs_orig[sample_idx, :, electrode]\n",
        "\n",
        "#                 # Target (ground truth future)\n",
        "#                 target_signal = targets_orig[sample_idx, :, electrode]\n",
        "\n",
        "#                 # Prediction\n",
        "#                 pred_signal = predictions_orig[sample_idx, :, electrode]\n",
        "\n",
        "#                 # Reconstruction\n",
        "#                 recon_signal = reconstruction_orig[sample_idx, :, electrode]\n",
        "\n",
        "#                 # Time axes\n",
        "#                 context_time = np.arange(context_size)\n",
        "#                 future_time = np.arange(context_size, context_size + predict_size)\n",
        "\n",
        "#                 # Plot\n",
        "#                 ax.plot(context_time, context_signal, 'b-', label='Context', alpha=0.7)\n",
        "#                 ax.plot(context_time, recon_signal, 'g--', label='Reconstruction', alpha=0.7)\n",
        "#                 ax.plot(future_time, target_signal, 'k-', label='Target', linewidth=2)\n",
        "#                 ax.plot(future_time, pred_signal, 'r--', label='Prediction', linewidth=2)\n",
        "\n",
        "#                 # Compute metrics\n",
        "#                 mse = np.mean((pred_signal - target_signal)**2)\n",
        "#                 corr = np.corrcoef(pred_signal, target_signal)[0, 1]\n",
        "\n",
        "#                 ax.set_title(f'Sample {sample_idx+1}, Electrode {electrode} | MSE: {mse:.4f}, Corr: {corr:.3f}')\n",
        "#                 ax.set_xlabel('Time (ms)')\n",
        "#                 ax.set_ylabel('Amplitude (Î¼V)')\n",
        "#                 ax.legend()\n",
        "#                 ax.grid(True, alpha=0.3)\n",
        "\n",
        "#         plt.suptitle(f'Signal Reconstructions - Epoch {epoch}', fontsize=16)\n",
        "#         plt.tight_layout()\n",
        "\n",
        "#         # Save figure\n",
        "#         save_path = os.path.join(save_dir, f'reconstructions_epoch_{epoch}.png')\n",
        "#         plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "#         plt.close()\n",
        "\n",
        "#         print(f\"Saved reconstruction visualization to {save_path}\")\n",
        "\n",
        "# def plot_training_history(history, save_dir):\n",
        "#     \"\"\"Plot training history.\"\"\"\n",
        "#     fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "#     # Loss curves\n",
        "#     axes[0, 0].plot(history['train_loss'], label='Train')\n",
        "#     axes[0, 0].plot(history['val_loss'], label='Validation')\n",
        "#     axes[0, 0].set_xlabel('Epoch')\n",
        "#     axes[0, 0].set_ylabel('Total Loss')\n",
        "#     axes[0, 0].set_title('Training Progress')\n",
        "#     axes[0, 0].legend()\n",
        "#     axes[0, 0].grid(True)\n",
        "\n",
        "#     # Individual losses\n",
        "#     loss_types = ['primary_loss', 'freq_loss', 'smooth_loss', 'recon_loss']\n",
        "#     for loss_type in loss_types:\n",
        "#         if f'train_{loss_type}' in history:\n",
        "#             axes[0, 1].plot(history[f'train_{loss_type}'], label=loss_type)\n",
        "#     axes[0, 1].set_xlabel('Epoch')\n",
        "#     axes[0, 1].set_ylabel('Loss')\n",
        "#     axes[0, 1].set_title('Loss Components')\n",
        "#     axes[0, 1].legend()\n",
        "#     axes[0, 1].grid(True)\n",
        "\n",
        "#     # Metrics\n",
        "#     if 'val_mse' in history:\n",
        "#         axes[1, 0].plot(history['val_mse'], label='MSE')\n",
        "#         axes[1, 0].set_xlabel('Epoch')\n",
        "#         axes[1, 0].set_ylabel('MSE')\n",
        "#         axes[1, 0].set_title('Validation MSE')\n",
        "#         axes[1, 0].grid(True)\n",
        "\n",
        "#     if 'val_corr' in history:\n",
        "#         axes[1, 1].plot(history['val_corr'], label='Correlation')\n",
        "#         axes[1, 1].set_xlabel('Epoch')\n",
        "#         axes[1, 1].set_ylabel('Correlation')\n",
        "#         axes[1, 1].set_title('Validation Correlation')\n",
        "#         axes[1, 1].grid(True)\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.savefig(os.path.join(save_dir, 'training_history.png'), dpi=150)\n",
        "#     plt.close()\n",
        "\n",
        "# #----------------------------------------------------------------------\n",
        "# # Training Functions\n",
        "# #----------------------------------------------------------------------\n",
        "\n",
        "# def train_epoch(model, train_loader, optimizer, criterion, device, epoch):\n",
        "#     \"\"\"Train for one epoch.\"\"\"\n",
        "#     model.train()\n",
        "\n",
        "#     losses = defaultdict(float)\n",
        "\n",
        "#     progress_bar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
        "#     for batch_data in progress_bar:\n",
        "#         inputs, targets = batch_data\n",
        "#         inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "#         targets = targets.to(device)\n",
        "\n",
        "#         # Forward pass\n",
        "#         predictions, aux_outputs = model(inputs, return_perspectives=True)\n",
        "\n",
        "#         # Add input data for reconstruction loss\n",
        "#         aux_outputs['input_data'] = inputs['raw']\n",
        "\n",
        "#         # Compute loss\n",
        "#         loss_dict = criterion(predictions, targets, aux_outputs)\n",
        "#         total_loss = loss_dict['total_loss']\n",
        "\n",
        "#         # Backward pass\n",
        "#         optimizer.zero_grad()\n",
        "#         total_loss.backward()\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), config.CLIP_GRAD_NORM)\n",
        "#         optimizer.step()\n",
        "\n",
        "#         # Track losses\n",
        "#         for key, value in loss_dict.items():\n",
        "#             losses[key] += value.item()\n",
        "\n",
        "#         # Update progress bar\n",
        "#         progress_bar.set_postfix({\n",
        "#             'loss': f\"{total_loss.item():.4f}\",\n",
        "#             'primary': f\"{loss_dict['primary_loss'].item():.4f}\"\n",
        "#         })\n",
        "\n",
        "#     # Average losses\n",
        "#     for key in losses:\n",
        "#         losses[key] /= len(train_loader)\n",
        "\n",
        "#     return losses\n",
        "\n",
        "# def evaluate(model, val_loader, criterion, device):\n",
        "#     \"\"\"Evaluate model.\"\"\"\n",
        "#     model.eval()\n",
        "\n",
        "#     losses = defaultdict(float)\n",
        "#     all_predictions = []\n",
        "#     all_targets = []\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for batch_data in val_loader:\n",
        "#             inputs, targets = batch_data\n",
        "#             inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "#             targets = targets.to(device)\n",
        "\n",
        "#             # Forward pass\n",
        "#             predictions, aux_outputs = model(inputs, return_perspectives=True)\n",
        "\n",
        "#             # Add input data for reconstruction loss\n",
        "#             aux_outputs['input_data'] = inputs['raw']\n",
        "\n",
        "#             # Compute loss\n",
        "#             loss_dict = criterion(predictions, targets, aux_outputs)\n",
        "\n",
        "#             # Track losses\n",
        "#             for key, value in loss_dict.items():\n",
        "#                 losses[key] += value.item()\n",
        "\n",
        "#             # Store predictions\n",
        "#             all_predictions.append(predictions.cpu().numpy())\n",
        "#             all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "#     # Average losses\n",
        "#     for key in losses:\n",
        "#         losses[key] /= len(val_loader)\n",
        "\n",
        "#     # Compute metrics\n",
        "#     all_predictions = np.concatenate(all_predictions, axis=0)\n",
        "#     all_targets = np.concatenate(all_targets, axis=0)\n",
        "\n",
        "#     # MSE and correlation\n",
        "#     mse = np.mean((all_predictions - all_targets)**2)\n",
        "\n",
        "#     # Average correlation across electrodes\n",
        "#     correlations = []\n",
        "#     for e in range(all_predictions.shape[2]):\n",
        "#         pred_e = all_predictions[:, :, e].flatten()\n",
        "#         target_e = all_targets[:, :, e].flatten()\n",
        "#         if np.std(pred_e) > 0 and np.std(target_e) > 0:\n",
        "#             corr = np.corrcoef(pred_e, target_e)[0, 1]\n",
        "#             correlations.append(corr)\n",
        "\n",
        "#     avg_corr = np.mean(correlations) if correlations else 0\n",
        "\n",
        "#     losses['mse'] = mse\n",
        "#     losses['corr'] = avg_corr\n",
        "\n",
        "#     return losses\n",
        "\n",
        "# def train_model(model, train_loader, val_loader, config, scaler, test_loader=None):\n",
        "#     \"\"\"Complete training pipeline.\"\"\"\n",
        "#     criterion = ComprehensiveLoss(config)\n",
        "#     optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE,\n",
        "#                                  weight_decay=config.WEIGHT_DECAY)\n",
        "#     scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, min_lr=1e-6)\n",
        "\n",
        "#     history = defaultdict(list)\n",
        "#     best_val_loss = float('inf')\n",
        "#     patience_counter = 0\n",
        "\n",
        "#     print(f\"Starting training for {config.EPOCHS} epochs...\")\n",
        "\n",
        "#     for epoch in range(config.EPOCHS):\n",
        "#         print(f\"\\n{'='*50}\")\n",
        "#         print(f\"Epoch {epoch+1}/{config.EPOCHS}\")\n",
        "#         print(f\"{'='*50}\")\n",
        "\n",
        "#         # Train\n",
        "#         train_losses = train_epoch(model, train_loader, optimizer, criterion, device, epoch+1)\n",
        "\n",
        "#         # Evaluate\n",
        "#         val_losses = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "#         # Update scheduler\n",
        "#         scheduler.step(val_losses['total_loss'])\n",
        "\n",
        "#         # Store history\n",
        "#         for key, value in train_losses.items():\n",
        "#             history[f'train_{key}'].append(value)\n",
        "#         for key, value in val_losses.items():\n",
        "#             history[f'val_{key}'].append(value)\n",
        "\n",
        "#         # Print results\n",
        "#         print(f\"Train Loss: {train_losses['total_loss']:.4f} | Val Loss: {val_losses['total_loss']:.4f}\")\n",
        "#         print(f\"Val MSE: {val_losses['mse']:.4f} | Val Corr: {val_losses['corr']:.3f}\")\n",
        "\n",
        "#         # Visualize reconstructions\n",
        "#         if (epoch + 1) % config.VISUALIZE_EVERY_N_EPOCHS == 0:\n",
        "#             visualize_reconstructions(\n",
        "#                 model, val_loader, scaler, epoch+1,\n",
        "#                 os.path.join(config.OUTPUT_DIR, 'reconstructions'),\n",
        "#                 num_samples=config.NUM_SAMPLES_TO_VISUALIZE\n",
        "#             )\n",
        "\n",
        "#         # Save best model\n",
        "#         if val_losses['total_loss'] < best_val_loss:\n",
        "#             best_val_loss = val_losses['total_loss']\n",
        "#             patience_counter = 0\n",
        "#             torch.save({\n",
        "#                 'epoch': epoch,\n",
        "#                 'model_state_dict': model.state_dict(),\n",
        "#                 'optimizer_state_dict': optimizer.state_dict(),\n",
        "#                 'val_loss': best_val_loss,\n",
        "#                 'config': config\n",
        "#             }, os.path.join(config.OUTPUT_DIR, 'models', 'best_model.pt'))\n",
        "#             print(f\"Saved best model with val loss: {best_val_loss:.4f}\")\n",
        "#         else:\n",
        "#             patience_counter += 1\n",
        "\n",
        "#         # Early stopping\n",
        "#         if patience_counter >= config.PATIENCE:\n",
        "#             print(f\"Early stopping after {epoch+1} epochs\")\n",
        "#             break\n",
        "\n",
        "#     # Final evaluation on test set\n",
        "#     if test_loader:\n",
        "#         print(\"\\nFinal evaluation on test set...\")\n",
        "#         test_losses = evaluate(model, test_loader, criterion, device)\n",
        "#         print(f\"Test Loss: {test_losses['total_loss']:.4f}\")\n",
        "#         print(f\"Test MSE: {test_losses['mse']:.4f} | Test Corr: {test_losses['corr']:.3f}\")\n",
        "\n",
        "#         # Save final test visualization\n",
        "#         visualize_reconstructions(\n",
        "#             model, test_loader, scaler, 'test',\n",
        "#             os.path.join(config.OUTPUT_DIR, 'reconstructions'),\n",
        "#             num_samples=10\n",
        "#         )\n",
        "\n",
        "#     # Plot training history\n",
        "#     plot_training_history(dict(history), config.OUTPUT_DIR)\n",
        "\n",
        "#     return model, history\n",
        "\n",
        "# #----------------------------------------------------------------------\n",
        "# # Main Pipeline\n",
        "# #----------------------------------------------------------------------\n",
        "\n",
        "# def main(data_path):\n",
        "#     \"\"\"Main training pipeline.\"\"\"\n",
        "#     print(\"Starting Enhanced Single Reservoir Pipeline\")\n",
        "#     print(f\"Output directory: {config.OUTPUT_DIR}\")\n",
        "\n",
        "#     try:\n",
        "#         # Load electrode positions\n",
        "#         positions = load_electrode_positions(data_path)\n",
        "\n",
        "#         # Select electrodes\n",
        "#         channel_nums, selected_indices = select_electrodes_fixed(positions, config.NUM_ELECTRODES)\n",
        "\n",
        "#         # Load LFP data\n",
        "#         lfp_data = load_lfp_data(data_path, channel_nums)\n",
        "\n",
        "#         # Extract windows\n",
        "#         windows = extract_windows(lfp_data)\n",
        "\n",
        "#         if windows.shape[0] == 0:\n",
        "#             print(\"No valid windows extracted!\")\n",
        "#             return None\n",
        "\n",
        "#         # Preprocess data\n",
        "#         train_loader, val_loader, test_loader, scaler = preprocess_data(windows)\n",
        "\n",
        "#         # Create model\n",
        "#         model = EnhancedSingleReservoirESN(config).to(device)\n",
        "\n",
        "#         # Count parameters\n",
        "#         total_params = sum(p.numel() for p in model.parameters())\n",
        "#         trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "#         print(f\"Total parameters: {total_params:,}\")\n",
        "#         print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "#         # Train model\n",
        "#         model, history = train_model(model, train_loader, val_loader, config, scaler, test_loader)\n",
        "\n",
        "#         # Save final model\n",
        "#         torch.save(model.state_dict(),\n",
        "#                   os.path.join(config.OUTPUT_DIR, 'models', 'final_model.pt'))\n",
        "\n",
        "#         print(\"\\nTraining completed successfully!\")\n",
        "\n",
        "#         return model, scaler\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error in main pipeline: {e}\")\n",
        "#         traceback.print_exc()\n",
        "#         return None\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Data path resolution\n",
        "#     data_path = None\n",
        "\n",
        "#     if os.path.exists(\"/kaggle/input/ecog-landmark-mkn\"):\n",
        "#         data_path = \"/kaggle/input/ecog-landmark-mkn\"\n",
        "#     elif os.path.exists(\"/content/ecog-landmark-mkn\"):\n",
        "#         data_path = \"/content/ecog-landmark-mkn\"\n",
        "#     else:\n",
        "#         # Try to download or use local path\n",
        "#         try:\n",
        "#             import kagglehub\n",
        "#             data_path = kagglehub.dataset_download(\"arunramponnambalam/ecog-landmark-mkn\")\n",
        "#         except:\n",
        "#             data_path = input(\"Enter path to dataset: \")\n",
        "\n",
        "#     if data_path and os.path.exists(data_path):\n",
        "#         print(f\"Using dataset at: {data_path}\")\n",
        "#         model, scaler = main(data_path)\n",
        "#     else:\n",
        "#         print(f\"Dataset path not found: {data_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **V2**"
      ],
      "metadata": {
        "id": "PD-RX8Gkt64D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from scipy import signal\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
        "import traceback\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Seed setup\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Enhanced Configuration V2\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "class ConfigV2:\n",
        "    def __init__(self):\n",
        "        # Data parameters\n",
        "        self.NUM_ELECTRODES = 30\n",
        "        self.CONTEXT_SIZE = 100\n",
        "        self.PREDICT_SIZE = 50\n",
        "        self.WINDOW_SIZE = self.CONTEXT_SIZE + self.PREDICT_SIZE\n",
        "        self.SAMPLING_RATE = 1000\n",
        "        self.MAX_SEQUENCES = 800  # More data\n",
        "        self.BATCH_SIZE = 64  # Larger batch\n",
        "        self.STRIDE = 20  # More overlap\n",
        "\n",
        "        # Frequency bands - more detailed\n",
        "        self.FREQ_BANDS = [\n",
        "            (4, 8),         # Theta\n",
        "            (8, 13),        # Alpha\n",
        "            (13, 30),       # Beta\n",
        "            (30, 50),       # Low Gamma\n",
        "            (50, 80),       # Mid Gamma\n",
        "            (80, 120),      # High Gamma\n",
        "            (120, 200),     # Very High Gamma\n",
        "        ]\n",
        "\n",
        "        # Learning parameters\n",
        "        self.LEARNING_RATE = 5e-4  # Lower initial LR\n",
        "        self.WEIGHT_DECAY = 1e-5\n",
        "        self.EPOCHS = 200\n",
        "        self.PATIENCE = 30\n",
        "        self.CLIP_GRAD_NORM = 0.5  # More aggressive clipping\n",
        "\n",
        "        # Enhanced Reservoir parameters\n",
        "        self.RESERVOIR_SIZE = 2000  # Larger reservoir\n",
        "        self.SPECTRAL_RADIUS = 0.99  # Closer to edge of chaos\n",
        "        self.LEAKY_RATE = 0.15  # Faster dynamics\n",
        "        self.CONNECTIVITY = 0.05  # Sparser (5%)\n",
        "        self.INPUT_SCALING = 0.8  # Stronger input\n",
        "        self.NOISE_LEVEL = 0.005  # Less noise\n",
        "\n",
        "        # Multi-timescale processing\n",
        "        self.NUM_TIMESCALES = 3\n",
        "        self.TIMESCALE_FACTORS = [1.0, 0.5, 0.25]  # Fast, medium, slow\n",
        "\n",
        "        # Architecture\n",
        "        self.HIDDEN_SIZE = 512\n",
        "        self.READOUT_HIDDEN = 1024\n",
        "        self.DROPOUT = 0.15\n",
        "        self.NUM_HEADS = 16  # More attention heads\n",
        "\n",
        "        # Multi-perspective\n",
        "        self.ELECTRODE_PERSPECTIVE_DIM = 256\n",
        "        self.COMMON_SPACE_DIM = 512\n",
        "\n",
        "        # Loss weights - adjusted\n",
        "        self.TIME_LOSS_WEIGHT = 1.0\n",
        "        self.FREQ_LOSS_WEIGHT = 0.5\n",
        "        self.PHASE_LOSS_WEIGHT = 0.3\n",
        "        self.RECONSTRUCTION_LOSS_WEIGHT = 0.8  # Higher weight\n",
        "        self.SMOOTHNESS_PENALTY = 0.05  # Lower penalty\n",
        "        self.DIVERSITY_LOSS_WEIGHT = 0.1\n",
        "\n",
        "        # Output directory\n",
        "        self.OUTPUT_DIR = \"enhanced_esn_v2_results\"\n",
        "        self.create_directories()\n",
        "\n",
        "    def create_directories(self):\n",
        "        os.makedirs(self.OUTPUT_DIR, exist_ok=True)\n",
        "        for subdir in ['models', 'reconstructions', 'analysis']:\n",
        "            os.makedirs(os.path.join(self.OUTPUT_DIR, subdir), exist_ok=True)\n",
        "\n",
        "config = ConfigV2()\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Data Loading (same as before)\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "def find_data_file(path, filename):\n",
        "    \"\"\"Find file in directory tree.\"\"\"\n",
        "    data_file = os.path.join(path, filename)\n",
        "    if os.path.exists(data_file):\n",
        "        return data_file\n",
        "\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        if filename in files:\n",
        "            return os.path.join(root, filename)\n",
        "\n",
        "    raise FileNotFoundError(f\"Could not find {filename} in {path}\")\n",
        "\n",
        "def load_electrode_positions(path):\n",
        "    \"\"\"Load electrode positions.\"\"\"\n",
        "    positions_file = find_data_file(path, 'limbic_insular_probe_channels.csv')\n",
        "    positions = pd.read_csv(positions_file)\n",
        "    positions = positions.rename(columns={\n",
        "        'channel_index': 'channel_num',\n",
        "        'probe_horizontal_position': 'x_position',\n",
        "        'probe_vertical_position': 'y_position'\n",
        "    })\n",
        "    return positions\n",
        "\n",
        "def select_electrodes_fixed(positions, num_electrodes=None):\n",
        "    \"\"\"Select electrodes with spatial coverage.\"\"\"\n",
        "    if num_electrodes is None:\n",
        "        num_electrodes = config.NUM_ELECTRODES\n",
        "\n",
        "    num_electrodes = min(num_electrodes, len(positions))\n",
        "\n",
        "    if num_electrodes == len(positions):\n",
        "        return positions['channel_num'].astype(int).values, list(range(len(positions)))\n",
        "\n",
        "    # K-means selection\n",
        "    from sklearn.cluster import KMeans\n",
        "    coords = positions[['x_position', 'y_position']].values\n",
        "    coords_norm = (coords - coords.mean(axis=0)) / coords.std(axis=0)\n",
        "\n",
        "    kmeans = KMeans(n_clusters=num_electrodes, random_state=SEED)\n",
        "    kmeans.fit(coords_norm)\n",
        "\n",
        "    selected_indices = []\n",
        "    for i in range(num_electrodes):\n",
        "        cluster_mask = kmeans.labels_ == i\n",
        "        cluster_indices = np.where(cluster_mask)[0]\n",
        "        if len(cluster_indices) > 0:\n",
        "            center = kmeans.cluster_centers_[i]\n",
        "            distances = np.linalg.norm(coords_norm[cluster_indices] - center, axis=1)\n",
        "            selected_idx = cluster_indices[np.argmin(distances)]\n",
        "            selected_indices.append(selected_idx)\n",
        "\n",
        "    channel_nums = positions.iloc[selected_indices]['channel_num'].astype(int).values\n",
        "    return channel_nums, selected_indices\n",
        "\n",
        "def load_lfp_data(path, channel_nums, max_rows=500000):\n",
        "    \"\"\"Load LFP data.\"\"\"\n",
        "    data_file = find_data_file(path, 'limbic_insular_ieeg_data (7).csv')\n",
        "    cols_to_use = ['timestamp', 'presentation_id'] + [f'channel_{ch}' for ch in channel_nums]\n",
        "    data = pd.read_csv(data_file, usecols=cols_to_use, nrows=max_rows)\n",
        "    return data\n",
        "\n",
        "def extract_windows(data, context_size=None, predict_size=None, stride=None, max_windows=None):\n",
        "    \"\"\"Extract overlapping windows.\"\"\"\n",
        "    if context_size is None:\n",
        "        context_size = config.CONTEXT_SIZE\n",
        "    if predict_size is None:\n",
        "        predict_size = config.PREDICT_SIZE\n",
        "    if stride is None:\n",
        "        stride = config.STRIDE\n",
        "    if max_windows is None:\n",
        "        max_windows = config.MAX_SEQUENCES\n",
        "\n",
        "    data_cols = [col for col in data.columns if col.startswith('channel_')]\n",
        "    window_size = context_size + predict_size\n",
        "    windows = []\n",
        "\n",
        "    # Group by presentation_id if available\n",
        "    if 'presentation_id' in data.columns:\n",
        "        for pid, group in data.groupby('presentation_id'):\n",
        "            if len(group) < window_size:\n",
        "                continue\n",
        "\n",
        "            group_data = group[data_cols].values\n",
        "            for start in range(0, len(group_data) - window_size + 1, stride):\n",
        "                if len(windows) >= max_windows:\n",
        "                    break\n",
        "                window = group_data[start:start + window_size]\n",
        "                if not np.isnan(window).any():\n",
        "                    windows.append(window)\n",
        "\n",
        "            if len(windows) >= max_windows:\n",
        "                break\n",
        "    else:\n",
        "        data_values = data[data_cols].values\n",
        "        for start in range(0, len(data_values) - window_size + 1, stride):\n",
        "            if len(windows) >= max_windows:\n",
        "                break\n",
        "            window = data_values[start:start + window_size]\n",
        "            if not np.isnan(window).any():\n",
        "                windows.append(window)\n",
        "\n",
        "    return np.array(windows)\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Enhanced Feature Extraction\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "def extract_multiscale_features(windows, fs=1000):\n",
        "    \"\"\"Extract multi-scale features including phase and envelope.\"\"\"\n",
        "    n_samples, window_size, n_channels = windows.shape\n",
        "    n_bands = len(config.FREQ_BANDS)\n",
        "\n",
        "    # Initialize feature arrays\n",
        "    band_powers = np.zeros((n_samples, n_bands, n_channels))\n",
        "    band_phases = np.zeros((n_samples, n_bands, window_size, n_channels))\n",
        "    band_envelopes = np.zeros((n_samples, n_bands, window_size, n_channels))\n",
        "\n",
        "    print(\"Extracting multi-scale features...\")\n",
        "\n",
        "    for band_idx, (low_freq, high_freq) in enumerate(config.FREQ_BANDS):\n",
        "        print(f\"Processing band {band_idx+1}/{n_bands}: {low_freq}-{high_freq} Hz\")\n",
        "\n",
        "        # Design filter\n",
        "        nyquist = fs / 2\n",
        "        low = low_freq / nyquist\n",
        "        high = high_freq / nyquist\n",
        "        sos = signal.butter(4, [low, high], btype='bandpass', output='sos')\n",
        "\n",
        "        for i in tqdm(range(n_samples), desc=f\"Band {band_idx+1}\"):\n",
        "            for j in range(n_channels):\n",
        "                # Filter signal\n",
        "                filtered = signal.sosfiltfilt(sos, windows[i, :, j])\n",
        "\n",
        "                # Hilbert transform for envelope and phase\n",
        "                analytic = signal.hilbert(filtered)\n",
        "                envelope = np.abs(analytic)\n",
        "                phase = np.angle(analytic)\n",
        "\n",
        "                # Store features\n",
        "                band_powers[i, band_idx, j] = np.mean(envelope**2)\n",
        "                band_envelopes[i, band_idx, :, j] = envelope\n",
        "                band_phases[i, band_idx, :, j] = phase\n",
        "\n",
        "    return {\n",
        "        'band_powers': band_powers,\n",
        "        'band_envelopes': band_envelopes,\n",
        "        'band_phases': band_phases\n",
        "    }\n",
        "\n",
        "def preprocess_data_v2(windows):\n",
        "    \"\"\"Enhanced preprocessing with multi-scale features.\"\"\"\n",
        "    num_windows, window_size, num_electrodes = windows.shape\n",
        "    context_size = config.CONTEXT_SIZE\n",
        "    predict_size = config.PREDICT_SIZE\n",
        "\n",
        "    # Split context and target\n",
        "    context_windows = windows[:, :context_size, :]\n",
        "    target_windows = windows[:, context_size:, :]\n",
        "\n",
        "    # Scale to microvolts\n",
        "    context_uv = context_windows * 1e6\n",
        "    target_uv = target_windows * 1e6\n",
        "\n",
        "    # Use RobustScaler for outlier handling\n",
        "    from sklearn.preprocessing import RobustScaler\n",
        "    scaler = RobustScaler(quantile_range=(5, 95))\n",
        "\n",
        "    # Fit on all data\n",
        "    all_data_flat = windows.reshape(-1, num_electrodes) * 1e6\n",
        "    scaler.fit(all_data_flat)\n",
        "\n",
        "    # Transform\n",
        "    context_scaled = scaler.transform(context_uv.reshape(-1, num_electrodes)).reshape(context_windows.shape)\n",
        "    target_scaled = scaler.transform(target_uv.reshape(-1, num_electrodes)).reshape(target_windows.shape)\n",
        "\n",
        "    # Extract features\n",
        "    features = extract_multiscale_features(context_uv)\n",
        "\n",
        "    # Create dataset\n",
        "    X_data = {\n",
        "        'raw': context_scaled,\n",
        "        'band_powers': features['band_powers'],\n",
        "        'band_envelopes': features['band_envelopes'][:, :, :context_size, :],\n",
        "        'band_phases': features['band_phases'][:, :, :context_size, :]\n",
        "    }\n",
        "\n",
        "    # Train/val/test split\n",
        "    indices = np.arange(len(context_scaled))\n",
        "    train_idx, temp_idx = train_test_split(indices, test_size=0.3, random_state=SEED)\n",
        "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=SEED)\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = EnhancedLFPDataset(\n",
        "        {k: v[train_idx] for k, v in X_data.items()},\n",
        "        target_scaled[train_idx]\n",
        "    )\n",
        "\n",
        "    val_dataset = EnhancedLFPDataset(\n",
        "        {k: v[val_idx] for k, v in X_data.items()},\n",
        "        target_scaled[val_idx]\n",
        "    )\n",
        "\n",
        "    test_dataset = EnhancedLFPDataset(\n",
        "        {k: v[test_idx] for k, v in X_data.items()},\n",
        "        target_scaled[test_idx]\n",
        "    )\n",
        "\n",
        "    # Create loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True,\n",
        "                            num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False,\n",
        "                           num_workers=2, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader, test_loader, scaler\n",
        "\n",
        "class EnhancedLFPDataset(Dataset):\n",
        "    \"\"\"Dataset with multi-scale features.\"\"\"\n",
        "    def __init__(self, X, y):\n",
        "        self.X_raw = torch.FloatTensor(X['raw'])\n",
        "        self.X_band_powers = torch.FloatTensor(X['band_powers'])\n",
        "        self.X_band_envelopes = torch.FloatTensor(X['band_envelopes'])\n",
        "        self.X_band_phases = torch.FloatTensor(X['band_phases'])\n",
        "        self.y = torch.FloatTensor(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'raw': self.X_raw[idx],\n",
        "            'band_powers': self.X_band_powers[idx],\n",
        "            'band_envelopes': self.X_band_envelopes[idx],\n",
        "            'band_phases': self.X_band_phases[idx]\n",
        "        }, self.y[idx]\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Multi-Timescale Reservoir\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "class SubReservoir(nn.Module):\n",
        "    \"\"\"\n",
        "    A single timescale reservoir submodule.\n",
        "    Contains a fixed weight matrix W and a leak rate buffer.\n",
        "    \"\"\"\n",
        "    def __init__(self, W: torch.Tensor, leak_rate: float):\n",
        "        super().__init__()\n",
        "        self.W = nn.Parameter(W, requires_grad=False)\n",
        "        self.register_buffer('leak_rate', torch.tensor(leak_rate))\n",
        "\n",
        "    def forward(self, prev_state: torch.Tensor, input_contrib: torch.Tensor, noise_level: float, training: bool):\n",
        "        rec = prev_state @ self.W.T\n",
        "        activation = torch.tanh(input_contrib + rec)\n",
        "        new_state = (1 - self.leak_rate) * prev_state + self.leak_rate * activation\n",
        "        if training and noise_level > 0:\n",
        "            new_state = new_state + torch.randn_like(new_state) * noise_level\n",
        "        return new_state\n",
        "\n",
        "class MultiTimescaleReservoir(nn.Module):\n",
        "    \"\"\"\n",
        "    Reservoir with multiple timescales. Ensures effective reservoir size matches submodules.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_timescales = config.NUM_TIMESCALES\n",
        "        # Base sub-reservoir size\n",
        "        self.sub_size = config.RESERVOIR_SIZE // self.num_timescales\n",
        "        # Effective total size = sub_size * num_timescales (handles non-divisible cases)\n",
        "        self.eff_res_size = self.sub_size * self.num_timescales\n",
        "\n",
        "        self.sub_reservoirs = nn.ModuleList()\n",
        "        self.input_projections = nn.ModuleList()\n",
        "        for timescale in config.TIMESCALE_FACTORS:\n",
        "            W = self._init_W(self.sub_size, config.CONNECTIVITY, config.SPECTRAL_RADIUS)\n",
        "            leak_rate = config.LEAKY_RATE * timescale\n",
        "            self.sub_reservoirs.append(SubReservoir(W, leak_rate))\n",
        "\n",
        "            proj = nn.Linear(config.NUM_ELECTRODES, self.sub_size, bias=False)\n",
        "            nn.init.uniform_(proj.weight, -config.INPUT_SCALING, config.INPUT_SCALING)\n",
        "            self.input_projections.append(proj)\n",
        "\n",
        "        # Cross-timescale connections now use eff_res_size\n",
        "        self.cross_connections = nn.Linear(self.eff_res_size, self.eff_res_size, bias=False)\n",
        "        nn.init.sparse_(self.cross_connections.weight, sparsity=0.9)\n",
        "\n",
        "        # Output projection also uses eff_res_size\n",
        "        self.output_projection = nn.Sequential(\n",
        "            nn.Linear(self.eff_res_size, config.HIDDEN_SIZE),\n",
        "            nn.LayerNorm(config.HIDDEN_SIZE),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(config.DROPOUT)\n",
        "        )\n",
        "        self.states = None\n",
        "\n",
        "    def _init_W(self, size, connectivity, spectral_radius):\n",
        "        W = torch.zeros(size, size)\n",
        "        num_conn = int(connectivity * size * size)\n",
        "        idx = torch.randperm(size*size)[:num_conn]\n",
        "        i_idx = idx // size\n",
        "        j_idx = idx % size\n",
        "        mask = i_idx != j_idx\n",
        "        i_idx, j_idx = i_idx[mask], j_idx[mask]\n",
        "        W[i_idx, j_idx] = torch.randn(len(i_idx)) * 0.1\n",
        "        eigs = torch.linalg.eigvals(W)\n",
        "        curr_rad = torch.max(torch.abs(eigs)).item()\n",
        "        if curr_rad > 0:\n",
        "            W *= (spectral_radius / curr_rad)\n",
        "        return W\n",
        "\n",
        "    def reset_state(self, batch_size=1):\n",
        "        self.states = [\n",
        "            torch.zeros(batch_size, self.sub_size, device=self.cross_connections.weight.device)\n",
        "            for _ in range(self.num_timescales)\n",
        "        ]\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch = x.size(0)\n",
        "        if self.states is None or self.states[0].size(0) != batch:\n",
        "            self.reset_state(batch)\n",
        "\n",
        "        new_states = []\n",
        "        for i, sub in enumerate(self.sub_reservoirs):\n",
        "            inp = self.input_projections[i](x)\n",
        "            state = sub(\n",
        "                prev_state=self.states[i],\n",
        "                input_contrib=inp,\n",
        "                noise_level=self.config.NOISE_LEVEL,\n",
        "                training=self.training\n",
        "            )\n",
        "            new_states.append(state)\n",
        "        self.states = new_states\n",
        "\n",
        "        combined = torch.cat(self.states, dim=1)\n",
        "        # combined now shape [batch, eff_res_size]\n",
        "        cc = self.cross_connections(combined)\n",
        "        combined = combined + 0.1 * torch.tanh(cc)\n",
        "\n",
        "        out = self.output_projection(combined)\n",
        "        return out, combined\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Attention Mechanisms\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    \"\"\"Efficient multi-head self-attention.\"\"\"\n",
        "\n",
        "    def __init__(self, d_model, n_heads=8, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_k = d_model // n_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "\n",
        "        # Linear transformations and split into heads\n",
        "        Q = self.W_q(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.W_k(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.W_v(x).view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Attention scores\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.d_k)\n",
        "\n",
        "        if mask is not None:\n",
        "            scores.masked_fill_(mask == 0, -1e9)\n",
        "\n",
        "        # Attention weights\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Apply attention\n",
        "        context = torch.matmul(attn_weights, V)\n",
        "\n",
        "        # Concatenate heads\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
        "\n",
        "        # Output projection\n",
        "        output = self.W_o(context)\n",
        "\n",
        "        # Residual connection and layer norm\n",
        "        output = self.layer_norm(x + self.dropout(output))\n",
        "\n",
        "        return output, attn_weights\n",
        "\n",
        "class TemporalConvEncoder(nn.Module):\n",
        "    \"\"\"Temporal convolutional encoder for capturing local patterns.\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_sizes=[3, 5, 7]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(input_dim, hidden_dim // len(kernel_sizes),\n",
        "                     kernel_size=k, padding=k//2)\n",
        "            for k in kernel_sizes\n",
        "        ])\n",
        "\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "        self.activation = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch, time, features]\n",
        "        x = x.transpose(1, 2)  # [batch, features, time]\n",
        "\n",
        "        # Apply multiple convolutions\n",
        "        conv_outputs = []\n",
        "        for conv in self.convs:\n",
        "            conv_out = self.activation(conv(x))\n",
        "            conv_outputs.append(conv_out)\n",
        "\n",
        "        # Concatenate\n",
        "        output = torch.cat(conv_outputs, dim=1)  # [batch, hidden_dim, time]\n",
        "        output = output.transpose(1, 2)  # [batch, time, hidden_dim]\n",
        "\n",
        "        return self.norm(output)\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Enhanced Main Model\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "class EnhancedESNv2(nn.Module):\n",
        "    \"\"\"Enhanced ESN with multi-timescale reservoir and advanced architecture.\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_electrodes = config.NUM_ELECTRODES\n",
        "        self.num_bands = len(config.FREQ_BANDS)\n",
        "\n",
        "        # Multi-scale feature extraction\n",
        "        self.band_encoder = nn.Sequential(\n",
        "            nn.Linear(self.num_bands * self.num_electrodes, config.HIDDEN_SIZE),\n",
        "            nn.LayerNorm(config.HIDDEN_SIZE),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(config.DROPOUT)\n",
        "        )\n",
        "\n",
        "        # Temporal convolutional encoder\n",
        "        self.temporal_encoder = TemporalConvEncoder(\n",
        "            input_dim=self.num_electrodes,\n",
        "            hidden_dim=config.HIDDEN_SIZE,\n",
        "            kernel_sizes=[3, 5, 7, 9]\n",
        "        )\n",
        "\n",
        "        # Multi-timescale reservoir\n",
        "        self.reservoir = MultiTimescaleReservoir(config)\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.self_attention = MultiHeadSelfAttention(\n",
        "            d_model=config.HIDDEN_SIZE,\n",
        "            n_heads=config.NUM_HEADS,\n",
        "            dropout=config.DROPOUT\n",
        "        )\n",
        "\n",
        "        # Electrode-specific encoders\n",
        "        self.electrode_encoders = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(config.HIDDEN_SIZE, config.ELECTRODE_PERSPECTIVE_DIM),\n",
        "                nn.LayerNorm(config.ELECTRODE_PERSPECTIVE_DIM),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(config.DROPOUT)\n",
        "            ) for _ in range(self.num_electrodes)\n",
        "        ])\n",
        "\n",
        "        # Cross-electrode attention\n",
        "        self.cross_electrode_attention = nn.MultiheadAttention(\n",
        "            embed_dim=config.ELECTRODE_PERSPECTIVE_DIM,\n",
        "            num_heads=8,\n",
        "            dropout=config.DROPOUT,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Temporal processor (GRU instead of LSTM for faster training)\n",
        "        self.temporal_processor = nn.GRU(\n",
        "            input_size = config.HIDDEN_SIZE + self.reservoir.eff_res_size,\n",
        "            hidden_size=config.READOUT_HIDDEN,\n",
        "            num_layers=3,\n",
        "            batch_first=True,\n",
        "            dropout=config.DROPOUT,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        # Prediction heads with skip connections\n",
        "        self.prediction_heads = nn.ModuleList()\n",
        "        for t in range(config.PREDICT_SIZE):\n",
        "            head = nn.Sequential(\n",
        "                nn.Linear(config.READOUT_HIDDEN * 2, config.READOUT_HIDDEN),\n",
        "                nn.LayerNorm(config.READOUT_HIDDEN),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(config.DROPOUT),\n",
        "                nn.Linear(config.READOUT_HIDDEN, self.num_electrodes)\n",
        "            )\n",
        "            self.prediction_heads.append(head)\n",
        "\n",
        "        # Direct pathway for residual predictions\n",
        "        self.direct_predictor = nn.Linear(self.num_electrodes, self.num_electrodes)\n",
        "\n",
        "        # Reconstruction decoder\n",
        "        self.reconstruction_decoder = nn.Sequential(\n",
        "            nn.Linear(config.ELECTRODE_PERSPECTIVE_DIM * self.num_electrodes,\n",
        "                     config.HIDDEN_SIZE * 2),\n",
        "            nn.LayerNorm(config.HIDDEN_SIZE * 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(config.DROPOUT),\n",
        "            nn.Linear(config.HIDDEN_SIZE * 2, config.HIDDEN_SIZE),\n",
        "            nn.LayerNorm(config.HIDDEN_SIZE),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(config.HIDDEN_SIZE, self.num_electrodes * config.CONTEXT_SIZE)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_dict, return_perspectives=False):\n",
        "        \"\"\"Forward pass with multi-scale processing.\"\"\"\n",
        "        x_raw = x_dict['raw']\n",
        "        x_band_powers = x_dict['band_powers']\n",
        "        x_band_envelopes = x_dict['band_envelopes']\n",
        "\n",
        "        batch_size, context_size, num_electrodes = x_raw.shape\n",
        "        device = x_raw.device\n",
        "\n",
        "        # Reset reservoir\n",
        "        self.reservoir.reset_state(batch_size)\n",
        "\n",
        "        # Storage\n",
        "        hidden_states = []\n",
        "        reservoir_states = []\n",
        "        electrode_perspectives = []\n",
        "\n",
        "        # Process sequence\n",
        "        for t in range(context_size):\n",
        "            # Get current timestep\n",
        "            x_t = x_raw[:, t, :]\n",
        "\n",
        "            # Band power features\n",
        "            band_features = x_band_powers.reshape(batch_size, -1)\n",
        "            band_encoded = self.band_encoder(band_features)\n",
        "\n",
        "            # Temporal convolution features (use small window around t)\n",
        "            window_start = max(0, t - 2)\n",
        "            window_end = min(context_size, t + 3)\n",
        "            x_window = x_raw[:, window_start:window_end, :]\n",
        "\n",
        "            # Pad if necessary\n",
        "            if x_window.shape[1] < 5:\n",
        "                pad_size = 5 - x_window.shape[1]\n",
        "                x_window = F.pad(x_window, (0, 0, 0, pad_size), 'constant', 0)\n",
        "\n",
        "            temporal_features = self.temporal_encoder(x_window)\n",
        "            temporal_features = temporal_features[:, 2, :]  # Center of window\n",
        "\n",
        "            # Reservoir processing\n",
        "            reservoir_out, reservoir_state = self.reservoir(x_t)\n",
        "\n",
        "            # Combine features\n",
        "            combined = reservoir_out + 0.5 * band_encoded + 0.5 * temporal_features\n",
        "\n",
        "            hidden_states.append(combined)\n",
        "            reservoir_states.append(reservoir_state)\n",
        "\n",
        "        # Stack sequences\n",
        "        hidden_sequence = torch.stack(hidden_states, dim=1)\n",
        "        reservoir_sequence = torch.stack(reservoir_states, dim=1)\n",
        "\n",
        "        # Self-attention over time\n",
        "        attended_sequence, _ = self.self_attention(hidden_sequence)\n",
        "\n",
        "        # Extract electrode perspectives\n",
        "        if return_perspectives:\n",
        "            for e_idx in range(self.num_electrodes):\n",
        "                # Electrode-specific encoding\n",
        "                electrode_features = self.electrode_encoders[e_idx](attended_sequence)\n",
        "\n",
        "                # Average over time\n",
        "                electrode_perspective = electrode_features.mean(dim=1)\n",
        "                electrode_perspectives.append(electrode_perspective)\n",
        "\n",
        "            # Stack and apply cross-electrode attention\n",
        "            electrode_perspectives_stacked = torch.stack(electrode_perspectives, dim=1)\n",
        "            attended_perspectives, _ = self.cross_electrode_attention(\n",
        "                electrode_perspectives_stacked,\n",
        "                electrode_perspectives_stacked,\n",
        "                electrode_perspectives_stacked\n",
        "            )\n",
        "\n",
        "        # Combine hidden and reservoir states\n",
        "        combined_sequence = torch.cat([attended_sequence, reservoir_sequence], dim=2)\n",
        "\n",
        "        # Temporal processing\n",
        "        gru_out, _ = self.temporal_processor(combined_sequence)\n",
        "\n",
        "        # Get last hidden state\n",
        "        final_hidden = gru_out[:, -1, :]\n",
        "\n",
        "        # Generate predictions\n",
        "        predictions = []\n",
        "        hidden = final_hidden\n",
        "\n",
        "        # Use last context as base for residual prediction\n",
        "        last_context = x_raw[:, -1, :]\n",
        "\n",
        "        for t in range(config.PREDICT_SIZE):\n",
        "            # Main prediction\n",
        "            pred_main = self.prediction_heads[t](hidden)\n",
        "\n",
        "            # Residual prediction\n",
        "            pred_residual = self.direct_predictor(last_context)\n",
        "\n",
        "            # Combine predictions\n",
        "            pred_t = pred_main + 0.1 * pred_residual\n",
        "            predictions.append(pred_t)\n",
        "\n",
        "            # Update for next step\n",
        "            if t < config.PREDICT_SIZE - 1:\n",
        "                # Simple autoregressive update\n",
        "                hidden = hidden * 0.95  # Decay\n",
        "                last_context = pred_t.detach()  # Use prediction as context\n",
        "\n",
        "        # Stack predictions\n",
        "        predictions = torch.stack(predictions, dim=1)\n",
        "\n",
        "        if return_perspectives:\n",
        "            # Reconstruction\n",
        "            all_perspectives = torch.cat(electrode_perspectives, dim=1)\n",
        "            reconstruction = self.reconstruction_decoder(all_perspectives)\n",
        "            reconstruction = reconstruction.view(batch_size, context_size, num_electrodes)\n",
        "\n",
        "            return predictions, {\n",
        "                'reconstruction': reconstruction,\n",
        "                'electrode_perspectives': electrode_perspectives,\n",
        "                'attended_sequence': attended_sequence\n",
        "            }\n",
        "        else:\n",
        "            return predictions\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Enhanced Loss Functions\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "class EnhancedLoss(nn.Module):\n",
        "    \"\"\"Comprehensive loss with multiple components.\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "    def spectral_loss(self, pred, target, fs=1000):\n",
        "        \"\"\"Loss in frequency domain with focus on gamma.\"\"\"\n",
        "        # Compute power spectral density\n",
        "        pred_fft = torch.fft.rfft(pred, dim=1)\n",
        "        target_fft = torch.fft.rfft(target, dim=1)\n",
        "\n",
        "        pred_psd = torch.abs(pred_fft)**2\n",
        "        target_psd = torch.abs(target_fft)**2\n",
        "\n",
        "        # Frequency bins\n",
        "        n_fft = pred_psd.shape[1]\n",
        "        freqs = torch.fft.rfftfreq(pred.shape[1], 1/fs).to(pred.device)\n",
        "\n",
        "        # Gamma band mask (30-200 Hz)\n",
        "        gamma_mask = (freqs >= 30) & (freqs <= 200)\n",
        "\n",
        "        # Weighted spectral loss\n",
        "        spectral_loss = F.mse_loss(pred_psd, target_psd)\n",
        "        gamma_loss = F.mse_loss(pred_psd[:, gamma_mask], target_psd[:, gamma_mask])\n",
        "\n",
        "        return 0.5 * spectral_loss + 0.5 * gamma_loss\n",
        "\n",
        "    def phase_coherence_loss(self, pred, target):\n",
        "        \"\"\"Phase coherence loss for maintaining oscillatory structure.\"\"\"\n",
        "        # Hilbert transform for phase\n",
        "        pred_complex = torch.view_as_complex(\n",
        "            torch.stack([pred, torch.zeros_like(pred)], dim=-1)\n",
        "        )\n",
        "        target_complex = torch.view_as_complex(\n",
        "            torch.stack([target, torch.zeros_like(target)], dim=-1)\n",
        "        )\n",
        "\n",
        "        # Phase difference\n",
        "        phase_diff = torch.angle(pred_complex) - torch.angle(target_complex)\n",
        "\n",
        "        # Circular mean of phase differences\n",
        "        coherence = torch.abs(torch.mean(torch.exp(1j * phase_diff)))\n",
        "\n",
        "        return 1.0 - coherence.mean()\n",
        "\n",
        "    def smoothness_regularization(self, pred):\n",
        "        \"\"\"Penalize excessive high-frequency noise.\"\"\"\n",
        "        # Second-order differences\n",
        "        diff2 = pred[:, 2:, :] - 2*pred[:, 1:-1, :] + pred[:, :-2, :]\n",
        "        return torch.mean(diff2**2)\n",
        "\n",
        "    def forward(self, predictions, targets, aux_outputs=None):\n",
        "        \"\"\"Compute all loss components.\"\"\"\n",
        "        # Time domain loss (MSE + MAE for robustness)\n",
        "        time_loss = 0.7 * F.mse_loss(predictions, targets) + \\\n",
        "                   0.3 * F.l1_loss(predictions, targets)\n",
        "\n",
        "        # Frequency domain loss\n",
        "        freq_loss = 0\n",
        "        for e in range(predictions.shape[2]):\n",
        "            freq_loss += self.spectral_loss(predictions[:, :, e], targets[:, :, e])\n",
        "        freq_loss /= predictions.shape[2]\n",
        "\n",
        "        # Phase coherence\n",
        "        phase_loss = self.phase_coherence_loss(predictions, targets)\n",
        "\n",
        "        # Smoothness\n",
        "        smooth_loss = self.smoothness_regularization(predictions)\n",
        "\n",
        "        # Total prediction loss\n",
        "        total_loss = (\n",
        "            self.config.TIME_LOSS_WEIGHT * time_loss +\n",
        "            self.config.FREQ_LOSS_WEIGHT * freq_loss +\n",
        "            self.config.PHASE_LOSS_WEIGHT * phase_loss +\n",
        "            self.config.SMOOTHNESS_PENALTY * smooth_loss\n",
        "        )\n",
        "\n",
        "        # Reconstruction loss if available\n",
        "        recon_loss = torch.tensor(0.0, device=predictions.device)\n",
        "        if aux_outputs is not None and 'reconstruction' in aux_outputs and 'input_data' in aux_outputs:\n",
        "            reconstruction = aux_outputs['reconstruction']\n",
        "            input_data = aux_outputs['input_data']\n",
        "            recon_loss = F.mse_loss(reconstruction, input_data)\n",
        "            total_loss += self.config.RECONSTRUCTION_LOSS_WEIGHT * recon_loss\n",
        "\n",
        "        return {\n",
        "            'total_loss': total_loss,\n",
        "            'time_loss': time_loss,\n",
        "            'freq_loss': freq_loss,\n",
        "            'phase_loss': phase_loss,\n",
        "            'smooth_loss': smooth_loss,\n",
        "            'recon_loss': recon_loss\n",
        "        }\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Training with Improved Visualization\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "def visualize_predictions_v2(model, data_loader, scaler, epoch, save_dir, num_samples=5):\n",
        "    \"\"\"Enhanced visualization with spectral analysis.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        inputs, targets = next(iter(data_loader))\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Get predictions\n",
        "        predictions, aux_outputs = model(inputs, return_perspectives=True)\n",
        "\n",
        "        # Convert to numpy and inverse transform\n",
        "        inputs_np = inputs['raw'].cpu().numpy()\n",
        "        targets_np = targets.cpu().numpy()\n",
        "        predictions_np = predictions.cpu().numpy()\n",
        "        reconstruction_np = aux_outputs['reconstruction'].cpu().numpy()\n",
        "\n",
        "        # Inverse transform\n",
        "        batch_size, context_size, num_electrodes = inputs_np.shape\n",
        "        _, predict_size, _ = predictions_np.shape\n",
        "\n",
        "        # Reshape and inverse transform\n",
        "        inputs_orig = scaler.inverse_transform(\n",
        "            inputs_np.reshape(-1, num_electrodes)\n",
        "        ).reshape(batch_size, context_size, num_electrodes)\n",
        "\n",
        "        targets_orig = scaler.inverse_transform(\n",
        "            targets_np.reshape(-1, num_electrodes)\n",
        "        ).reshape(batch_size, predict_size, num_electrodes)\n",
        "\n",
        "        predictions_orig = scaler.inverse_transform(\n",
        "            predictions_np.reshape(-1, num_electrodes)\n",
        "        ).reshape(batch_size, predict_size, num_electrodes)\n",
        "\n",
        "        reconstruction_orig = scaler.inverse_transform(\n",
        "            reconstruction_np.reshape(-1, num_electrodes)\n",
        "        ).reshape(batch_size, context_size, num_electrodes)\n",
        "\n",
        "        # Create figure with spectral analysis\n",
        "        fig = plt.figure(figsize=(24, 5*num_samples))\n",
        "        gs = fig.add_gridspec(num_samples, 4, width_ratios=[3, 1, 3, 1])\n",
        "\n",
        "        for sample_idx in range(min(num_samples, batch_size)):\n",
        "            # Select diverse electrodes\n",
        "            electrode_indices = [0, num_electrodes//3, 2*num_electrodes//3, num_electrodes-1]\n",
        "\n",
        "            for e_idx, electrode in enumerate(electrode_indices[:2]):  # Show 2 electrodes per row\n",
        "                # Time domain plot\n",
        "                ax_time = fig.add_subplot(gs[sample_idx, e_idx*2])\n",
        "\n",
        "                # Signals\n",
        "                context_signal = inputs_orig[sample_idx, :, electrode]\n",
        "                target_signal = targets_orig[sample_idx, :, electrode]\n",
        "                pred_signal = predictions_orig[sample_idx, :, electrode]\n",
        "                recon_signal = reconstruction_orig[sample_idx, :, electrode]\n",
        "\n",
        "                # Time axes\n",
        "                context_time = np.arange(context_size)\n",
        "                future_time = np.arange(context_size, context_size + predict_size)\n",
        "\n",
        "                # Plot\n",
        "                ax_time.plot(context_time, context_signal, 'b-', label='Context', alpha=0.7, linewidth=1.5)\n",
        "                ax_time.plot(context_time, recon_signal, 'g--', label='Reconstruction', alpha=0.7, linewidth=1.5)\n",
        "                ax_time.plot(future_time, target_signal, 'k-', label='Target', linewidth=2)\n",
        "                ax_time.plot(future_time, pred_signal, 'r--', label='Prediction', linewidth=2)\n",
        "\n",
        "                # Metrics\n",
        "                mse = np.mean((pred_signal - target_signal)**2)\n",
        "                corr = np.corrcoef(pred_signal, target_signal)[0, 1]\n",
        "\n",
        "                ax_time.set_title(f'Sample {sample_idx+1}, Electrode {electrode}\\nMSE: {mse:.4f}, Corr: {corr:.3f}')\n",
        "                ax_time.set_xlabel('Time (ms)')\n",
        "                ax_time.set_ylabel('Amplitude (Î¼V)')\n",
        "                ax_time.legend()\n",
        "                ax_time.grid(True, alpha=0.3)\n",
        "\n",
        "                # Spectral analysis\n",
        "                ax_spec = fig.add_subplot(gs[sample_idx, e_idx*2 + 1])\n",
        "\n",
        "                # Compute spectra\n",
        "                from scipy.signal import welch\n",
        "                f_target, psd_target = welch(target_signal, fs=1000, nperseg=min(64, len(target_signal)))\n",
        "                f_pred, psd_pred = welch(pred_signal, fs=1000, nperseg=min(64, len(pred_signal)))\n",
        "\n",
        "                # Plot spectra\n",
        "                ax_spec.semilogy(f_target, psd_target, 'k-', label='Target', linewidth=2)\n",
        "                ax_spec.semilogy(f_pred, psd_pred, 'r--', label='Prediction', linewidth=2)\n",
        "\n",
        "                # Highlight gamma band\n",
        "                ax_spec.axvspan(30, 200, alpha=0.2, color='yellow', label='Gamma')\n",
        "\n",
        "                ax_spec.set_xlabel('Frequency (Hz)')\n",
        "                ax_spec.set_ylabel('PSD')\n",
        "                ax_spec.set_xlim([0, 250])\n",
        "                ax_spec.legend()\n",
        "                ax_spec.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.suptitle(f'Enhanced Signal Reconstruction - Epoch {epoch}', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save\n",
        "        save_path = os.path.join(save_dir, f'reconstruction_v2_epoch_{epoch}.png')\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"Saved enhanced visualization to {save_path}\")\n",
        "\n",
        "def train_epoch_v2(model, train_loader, optimizer, criterion, device, epoch):\n",
        "    \"\"\"Training with gradient accumulation.\"\"\"\n",
        "    model.train()\n",
        "    losses = defaultdict(float)\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
        "\n",
        "    for i, (inputs, targets) in enumerate(progress_bar):\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        predictions, aux_outputs = model(inputs, return_perspectives=True)\n",
        "        aux_outputs['input_data'] = inputs['raw']\n",
        "\n",
        "        # Compute loss\n",
        "        loss_dict = criterion(predictions, targets, aux_outputs)\n",
        "        loss = loss_dict['total_loss']\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.CLIP_GRAD_NORM)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track losses\n",
        "        for key, value in loss_dict.items():\n",
        "            losses[key] += value.item()\n",
        "\n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': f\"{loss.item():.4f}\",\n",
        "            'time': f\"{loss_dict['time_loss'].item():.4f}\",\n",
        "            'freq': f\"{loss_dict['freq_loss'].item():.4f}\"\n",
        "        })\n",
        "\n",
        "    # Average losses\n",
        "    for key in losses:\n",
        "        losses[key] /= len(train_loader)\n",
        "\n",
        "    return losses\n",
        "\n",
        "def evaluate_v2(model, val_loader, criterion, device):\n",
        "    \"\"\"Evaluation with comprehensive metrics.\"\"\"\n",
        "    model.eval()\n",
        "    losses = defaultdict(float)\n",
        "    predictions_all = []\n",
        "    targets_all = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in tqdm(val_loader, desc='Evaluating'):\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            predictions, aux_outputs = model(inputs, return_perspectives=True)\n",
        "            aux_outputs['input_data'] = inputs['raw']\n",
        "\n",
        "            loss_dict = criterion(predictions, targets, aux_outputs)\n",
        "\n",
        "            for key, value in loss_dict.items():\n",
        "                losses[key] += value.item()\n",
        "\n",
        "            predictions_all.append(predictions.cpu().numpy())\n",
        "            targets_all.append(targets.cpu().numpy())\n",
        "\n",
        "    # Average losses\n",
        "    for key in losses:\n",
        "        losses[key] /= len(val_loader)\n",
        "\n",
        "    # Compute metrics\n",
        "    predictions_all = np.concatenate(predictions_all, axis=0)\n",
        "    targets_all = np.concatenate(targets_all, axis=0)\n",
        "\n",
        "    # MSE\n",
        "    mse = np.mean((predictions_all - targets_all)**2)\n",
        "\n",
        "    # Correlation per electrode\n",
        "    correlations = []\n",
        "    for e in range(predictions_all.shape[2]):\n",
        "        pred_e = predictions_all[:, :, e].flatten()\n",
        "        target_e = targets_all[:, :, e].flatten()\n",
        "        if np.std(pred_e) > 0 and np.std(target_e) > 0:\n",
        "            corr = np.corrcoef(pred_e, target_e)[0, 1]\n",
        "            if not np.isnan(corr):\n",
        "                correlations.append(corr)\n",
        "\n",
        "    avg_corr = np.mean(correlations) if correlations else 0\n",
        "\n",
        "    # R-squared\n",
        "    r2_scores = []\n",
        "    for e in range(predictions_all.shape[2]):\n",
        "        pred_e = predictions_all[:, :, e].flatten()\n",
        "        target_e = targets_all[:, :, e].flatten()\n",
        "        if np.var(target_e) > 0:\n",
        "            r2 = 1 - np.sum((target_e - pred_e)**2) / np.sum((target_e - np.mean(target_e))**2)\n",
        "            r2_scores.append(r2)\n",
        "\n",
        "    avg_r2 = np.mean(r2_scores) if r2_scores else 0\n",
        "\n",
        "    losses['mse'] = mse\n",
        "    losses['corr'] = avg_corr\n",
        "    losses['r2'] = avg_r2\n",
        "\n",
        "    return losses\n",
        "\n",
        "def train_model_v2(model, train_loader, val_loader, config, scaler, test_loader=None):\n",
        "    \"\"\"Complete training pipeline.\"\"\"\n",
        "    criterion = EnhancedLoss(config)\n",
        "\n",
        "    # Optimizer with different LR for different parts\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {'params': model.reservoir.parameters(), 'lr': config.LEARNING_RATE * 0.1},  # Lower LR for reservoir\n",
        "        {'params': model.temporal_encoder.parameters(), 'lr': config.LEARNING_RATE},\n",
        "        {'params': model.self_attention.parameters(), 'lr': config.LEARNING_RATE},\n",
        "        {'params': model.prediction_heads.parameters(), 'lr': config.LEARNING_RATE * 2}  # Higher LR for output\n",
        "    ], weight_decay=config.WEIGHT_DECAY)\n",
        "\n",
        "    # Cosine annealing with warm restarts\n",
        "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=2, eta_min=1e-6)\n",
        "\n",
        "    history = defaultdict(list)\n",
        "    best_val_loss = float('inf')\n",
        "    best_val_corr = 0\n",
        "    patience_counter = 0\n",
        "\n",
        "    print(f\"Starting enhanced training for {config.EPOCHS} epochs...\")\n",
        "\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Epoch {epoch+1}/{config.EPOCHS} | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Train\n",
        "        train_losses = train_epoch_v2(model, train_loader, optimizer, criterion, device, epoch+1)\n",
        "\n",
        "        # Evaluate\n",
        "        val_losses = evaluate_v2(model, val_loader, criterion, device)\n",
        "\n",
        "        # Update scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Store history\n",
        "        for key, value in train_losses.items():\n",
        "            history[f'train_{key}'].append(value)\n",
        "        for key, value in val_losses.items():\n",
        "            history[f'val_{key}'].append(value)\n",
        "\n",
        "        # Print results\n",
        "        print(f\"\\nTrain - Total: {train_losses['total_loss']:.4f}, Time: {train_losses['time_loss']:.4f}, \"\n",
        "              f\"Freq: {train_losses['freq_loss']:.4f}, Recon: {train_losses['recon_loss']:.4f}\")\n",
        "        print(f\"Val - Total: {val_losses['total_loss']:.4f}, MSE: {val_losses['mse']:.4f}, \"\n",
        "              f\"Corr: {val_losses['corr']:.3f}, RÂ²: {val_losses['r2']:.3f}\")\n",
        "\n",
        "        # Visualize\n",
        "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "            visualize_predictions_v2(\n",
        "                model, val_loader, scaler, epoch+1,\n",
        "                os.path.join(config.OUTPUT_DIR, 'reconstructions'),\n",
        "                num_samples=5\n",
        "            )\n",
        "\n",
        "        # Save best model\n",
        "        if val_losses['corr'] > best_val_corr:\n",
        "            best_val_corr = val_losses['corr']\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_corr': best_val_corr,\n",
        "                'val_losses': val_losses\n",
        "            }, os.path.join(config.OUTPUT_DIR, 'models', 'best_model_corr.pt'))\n",
        "            print(f\"Saved best model with correlation: {best_val_corr:.3f}\")\n",
        "\n",
        "        if val_losses['total_loss'] < best_val_loss:\n",
        "            best_val_loss = val_losses['total_loss']\n",
        "            patience_counter = 0\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_loss': best_val_loss\n",
        "            }, os.path.join(config.OUTPUT_DIR, 'models', 'best_model_loss.pt'))\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping\n",
        "        if patience_counter >= config.PATIENCE:\n",
        "            print(f\"Early stopping after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    # Test evaluation\n",
        "    if test_loader:\n",
        "        print(\"\\nFinal test evaluation...\")\n",
        "        test_losses = evaluate_v2(model, test_loader, criterion, device)\n",
        "        print(f\"Test - MSE: {test_losses['mse']:.4f}, Corr: {test_losses['corr']:.3f}, RÂ²: {test_losses['r2']:.3f}\")\n",
        "\n",
        "        visualize_predictions_v2(\n",
        "            model, test_loader, scaler, 'test',\n",
        "            os.path.join(config.OUTPUT_DIR, 'reconstructions'),\n",
        "            num_samples=10\n",
        "        )\n",
        "\n",
        "    return model, history\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# Main Pipeline\n",
        "#----------------------------------------------------------------------\n",
        "\n",
        "def main_v2(data_path):\n",
        "    \"\"\"Enhanced main pipeline.\"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"Enhanced ESN V2 - Multi-Timescale Biologically Plausible Model\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    try:\n",
        "        # Load data\n",
        "        positions = load_electrode_positions(data_path)\n",
        "        channel_nums, selected_indices = select_electrodes_fixed(positions)\n",
        "        lfp_data = load_lfp_data(data_path, channel_nums)\n",
        "\n",
        "        # Extract windows\n",
        "        windows = extract_windows(lfp_data)\n",
        "        print(f\"Extracted {windows.shape[0]} windows\")\n",
        "\n",
        "        # Preprocess with enhanced features\n",
        "        train_loader, val_loader, test_loader, scaler = preprocess_data_v2(windows)\n",
        "\n",
        "        # Create model\n",
        "        model = EnhancedESNv2(config).to(device)\n",
        "\n",
        "        # Print model info\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        print(f\"Model parameters - Total: {total_params:,}, Trainable: {trainable_params:,}\")\n",
        "\n",
        "        # Train\n",
        "        model, history = train_model_v2(model, train_loader, val_loader, config, scaler, test_loader)\n",
        "\n",
        "        print(\"\\nTraining completed successfully!\")\n",
        "        return model, scaler\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None, None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Data path resolution\n",
        "    data_path = None\n",
        "\n",
        "    if os.path.exists(\"/kaggle/input/ecog-landmark-mkn\"):\n",
        "        data_path = \"/kaggle/input/ecog-landmark-mkn\"\n",
        "    elif os.path.exists(\"/content/ecog-landmark-mkn\"):\n",
        "        data_path = \"/content/ecog-landmark-mkn\"\n",
        "    else:\n",
        "        try:\n",
        "            import kagglehub\n",
        "            data_path = kagglehub.dataset_download(\"arunramponnambalam/ecog-landmark-mkn\")\n",
        "        except:\n",
        "            data_path = input(\"Enter dataset path: \")\n",
        "\n",
        "    if data_path and os.path.exists(data_path):\n",
        "        print(f\"Using dataset at: {data_path}\")\n",
        "        model, scaler = main_v2(data_path)\n",
        "    else:\n",
        "        print(f\"Dataset not found: {data_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8j90-KNDrNHc",
        "outputId": "cc9422ca-9ee8-4e4b-87cb-38f1accf8144"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Using dataset at: /kaggle/input/ecog-landmark-mkn\n",
            "================================================================================\n",
            "Enhanced ESN V2 - Multi-Timescale Biologically Plausible Model\n",
            "================================================================================\n",
            "Extracted 800 windows\n",
            "Extracting multi-scale features...\n",
            "Processing band 1/7: 4-8 Hz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Band 1: 100%|ââââââââââ| 800/800 [00:16<00:00, 49.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing band 2/7: 8-13 Hz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Band 2: 100%|ââââââââââ| 800/800 [00:16<00:00, 49.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing band 3/7: 13-30 Hz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Band 3: 100%|ââââââââââ| 800/800 [00:16<00:00, 49.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing band 4/7: 30-50 Hz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Band 4: 100%|ââââââââââ| 800/800 [00:16<00:00, 49.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing band 5/7: 50-80 Hz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Band 5: 100%|ââââââââââ| 800/800 [00:16<00:00, 49.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing band 6/7: 80-120 Hz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Band 6: 100%|ââââââââââ| 800/800 [00:16<00:00, 48.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing band 7/7: 120-200 Hz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Band 7: 100%|ââââââââââ| 800/800 [00:16<00:00, 49.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters - Total: 187,860,234, Trainable: 186,529,566\n",
            "Starting enhanced training for 200 epochs...\n",
            "\n",
            "============================================================\n",
            "Epoch 1/200 | LR: 0.000050\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|ââââââââââ| 9/9 [00:08<00:00,  1.03it/s, loss=1769.6400, time=0.3954, freq=3537.4412]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 15718.5664, Time: 0.6156, Freq: 31434.8233, Recon: 0.2279\n",
            "Val - Total: 1873.7795, MSE: 0.3437, Corr: 0.019, RÂ²: -2.771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved enhanced visualization to enhanced_esn_v2_results/reconstructions/reconstruction_v2_epoch_1.png\n",
            "Saved best model with correlation: 0.019\n",
            "\n",
            "============================================================\n",
            "Epoch 2/200 | LR: 0.000050\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|ââââââââââ| 9/9 [00:06<00:00,  1.29it/s, loss=821.3833, time=0.2798, freq=1641.1815]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 1301.6575, Time: 0.3351, Freq: 2601.6092, Recon: 0.2278\n",
            "Val - Total: 1075.0524, MSE: 0.2123, Corr: 0.045, RÂ²: -1.356\n",
            "Saved best model with correlation: 0.045\n",
            "\n",
            "============================================================\n",
            "Epoch 3/200 | LR: 0.000049\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|ââââââââââ| 9/9 [00:06<00:00,  1.36it/s, loss=1012.4814, time=0.2408, freq=2023.5006]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 1030.7451, Time: 0.2621, Freq: 2059.9723, Recon: 0.2273\n",
            "Val - Total: 980.0897, MSE: 0.1909, Corr: 0.043, RÂ²: -1.138\n",
            "\n",
            "============================================================\n",
            "Epoch 4/200 | LR: 0.000047\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|ââââââââââ| 9/9 [00:06<00:00,  1.35it/s, loss=786.3887, time=0.2272, freq=1571.3575]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  3.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 828.8215, Time: 0.2390, Freq: 1656.1851, Recon: 0.2268\n",
            "Val - Total: 874.5592, MSE: 0.1778, Corr: 0.034, RÂ²: -0.993\n",
            "\n",
            "============================================================\n",
            "Epoch 5/200 | LR: 0.000045\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|ââââââââââ| 9/9 [00:06<00:00,  1.36it/s, loss=765.7691, time=0.2432, freq=1530.0579]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  3.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 712.6899, Time: 0.2334, Freq: 1423.9317, Recon: 0.2263\n",
            "Val - Total: 836.7971, MSE: 0.1755, Corr: 0.022, RÂ²: -0.981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved enhanced visualization to enhanced_esn_v2_results/reconstructions/reconstruction_v2_epoch_5.png\n",
            "\n",
            "============================================================\n",
            "Epoch 6/200 | LR: 0.000043\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|ââââââââââ| 9/9 [00:06<00:00,  1.35it/s, loss=466.3839, time=0.2209, freq=931.3479]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 614.4341, Time: 0.2246, Freq: 1227.4461, Recon: 0.2263\n",
            "Val - Total: 607.1563, MSE: 0.1592, Corr: 0.065, RÂ²: -0.784\n",
            "Saved best model with correlation: 0.065\n",
            "\n",
            "============================================================\n",
            "Epoch 7/200 | LR: 0.000040\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|ââââââââââ| 9/9 [00:06<00:00,  1.35it/s, loss=547.0149, time=0.2278, freq=1092.5961]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 502.6549, Time: 0.2200, Freq: 1003.8994, Recon: 0.2265\n",
            "Val - Total: 581.5910, MSE: 0.1661, Corr: 0.041, RÂ²: -0.860\n",
            "\n",
            "============================================================\n",
            "Epoch 8/200 | LR: 0.000037\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|ââââââââââ| 9/9 [00:06<00:00,  1.35it/s, loss=497.4702, time=0.2149, freq=993.5527]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 461.8109, Time: 0.2196, Freq: 922.2107, Recon: 0.2262\n",
            "Val - Total: 553.9359, MSE: 0.1604, Corr: 0.051, RÂ²: -0.808\n",
            "\n",
            "============================================================\n",
            "Epoch 9/200 | LR: 0.000033\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|ââââââââââ| 9/9 [00:06<00:00,  1.35it/s, loss=477.1280, time=0.2124, freq=952.8560]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 428.0083, Time: 0.2159, Freq: 854.6212, Recon: 0.2261\n",
            "Val - Total: 552.4408, MSE: 0.1524, Corr: 0.047, RÂ²: -0.714\n",
            "\n",
            "============================================================\n",
            "Epoch 10/200 | LR: 0.000029\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|ââââââââââ| 9/9 [00:06<00:00,  1.36it/s, loss=356.1078, time=0.2076, freq=710.8458]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  3.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 405.2417, Time: 0.2175, Freq: 809.0804, Recon: 0.2263\n",
            "Val - Total: 510.8385, MSE: 0.1517, Corr: 0.059, RÂ²: -0.707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved enhanced visualization to enhanced_esn_v2_results/reconstructions/reconstruction_v2_epoch_10.png\n",
            "\n",
            "============================================================\n",
            "Epoch 11/200 | LR: 0.000026\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|ââââââââââ| 9/9 [00:06<00:00,  1.35it/s, loss=333.7187, time=0.2226, freq=666.0239]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  3.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 351.1907, Time: 0.2130, Freq: 700.9900, Recon: 0.2267\n",
            "Val - Total: 450.6117, MSE: 0.1572, Corr: 0.045, RÂ²: -0.771\n",
            "\n",
            "============================================================\n",
            "Epoch 12/200 | LR: 0.000022\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|ââââââââââ| 9/9 [00:06<00:00,  1.34it/s, loss=243.4493, time=0.2120, freq=485.5200]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 316.7224, Time: 0.2153, Freq: 632.0508, Recon: 0.2267\n",
            "Val - Total: 419.5690, MSE: 0.1558, Corr: 0.057, RÂ²: -0.763\n",
            "\n",
            "============================================================\n",
            "Epoch 13/200 | LR: 0.000018\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|ââââââââââ| 9/9 [00:06<00:00,  1.35it/s, loss=286.6450, time=0.1907, freq=571.9791]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 280.8790, Time: 0.2148, Freq: 560.3675, Recon: 0.2262\n",
            "Val - Total: 436.6621, MSE: 0.1602, Corr: 0.050, RÂ²: -0.802\n",
            "\n",
            "============================================================\n",
            "Epoch 14/200 | LR: 0.000014\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|ââââââââââ| 9/9 [00:06<00:00,  1.35it/s, loss=274.9888, time=0.2325, freq=548.5300]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  3.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 256.2288, Time: 0.2155, Freq: 511.0623, Recon: 0.2269\n",
            "Val - Total: 393.6347, MSE: 0.1568, Corr: 0.055, RÂ²: -0.766\n",
            "\n",
            "============================================================\n",
            "Epoch 15/200 | LR: 0.000011\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|ââââââââââ| 9/9 [00:06<00:00,  1.35it/s, loss=213.1144, time=0.1992, freq=424.8656]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  3.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 226.8370, Time: 0.2151, Freq: 452.2786, Recon: 0.2267\n",
            "Val - Total: 381.9857, MSE: 0.1588, Corr: 0.051, RÂ²: -0.794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved enhanced visualization to enhanced_esn_v2_results/reconstructions/reconstruction_v2_epoch_15.png\n",
            "\n",
            "============================================================\n",
            "Epoch 16/200 | LR: 0.000008\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|ââââââââââ| 9/9 [00:06<00:00,  1.35it/s, loss=199.5848, time=0.2067, freq=397.8058]\n",
            "Evaluating: 100%|ââââââââââ| 2/2 [00:00<00:00,  3.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train - Total: 206.6465, Time: 0.2153, Freq: 411.8985, Recon: 0.2263\n",
            "Val - Total: 365.9469, MSE: 0.1561, Corr: 0.056, RÂ²: -0.759\n",
            "\n",
            "============================================================\n",
            "Epoch 17/200 | LR: 0.000006\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17:   0%|          | 0/9 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-1782678020.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Using dataset at: {data_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1239\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset not found: {data_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-6-1782678020.py\u001b[0m in \u001b[0;36mmain_v2\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining completed successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-6-1782678020.py\u001b[0m in \u001b[0;36mtrain_model_v2\u001b[0;34m(model, train_loader, val_loader, config, scaler, test_loader)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m         \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;31m# Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-6-1782678020.py\u001b[0m in \u001b[0;36mtrain_epoch_v2\u001b[0;34m(model, train_loader, optimizer, criterion, device, epoch)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_perspectives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m         \u001b[0maux_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-6-1782678020.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_dict, return_perspectives)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;31m# Main prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0mpred_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_heads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0;31m# Residual prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "git config --global user.name \"Krish0909\""
      ],
      "metadata": {
        "id": "QFBwHtFLuAyd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RQqsSIhV0cDu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}